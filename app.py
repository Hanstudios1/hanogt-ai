import streamlit as st
import google.generativeai as genai
import os
import io
import uuid
import time
from duckduckgo_search import DDGS
import requests
import re
import datetime
from PIL import Image
import numpy as np
import logging # Loglama iÃ§in

# --- Ä°steÄŸe BaÄŸlÄ± KÃ¼tÃ¼phaneler (Platforma Ã¶zel kurulum gerektirebilir) ---
# pyttsx3 ve speech_recognition genellikle Streamlit Cloud'da ek yapÄ±landÄ±rma gerektirir.
# Yerel geliÅŸtirme iÃ§in uygundur.
try:
    import pyttsx3
    import speech_recognition as sr
    TTS_SR_AVAILABLE = True
except ImportError:
    TTS_SR_AVAILABLE = False
    logging.warning("pyttsx3 veya speech_recognition modÃ¼lleri bulunamadÄ±. Sesli Ã¶zellikler devre dÄ±ÅŸÄ± bÄ±rakÄ±ldÄ±.")
    st.warning("Sesli sohbet ve metin okuma Ã¶zellikleri ÅŸu anda kullanÄ±lamÄ±yor. Gerekli kÃ¼tÃ¼phaneler yÃ¼klenmemiÅŸ veya uyumlu deÄŸil.")

# --- Global DeÄŸiÅŸkenler ve Ayarlar ---
# Loglama yapÄ±landÄ±rmasÄ±
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# API AnahtarÄ± KontrolÃ¼
# Streamlit Secrets (Cloud) veya .env (Yerel) kullanÄ±mÄ±
GOOGLE_API_KEY = st.secrets.get("GOOGLE_API_KEY") if st.secrets else os.environ.get("GOOGLE_API_KEY")

if not GOOGLE_API_KEY:
    st.error("GOOGLE_API_KEY bulunamadÄ±. LÃ¼tfen Streamlit Secrets'Ä± veya ortam deÄŸiÅŸkenlerini kontrol edin.")
    logger.error("GOOGLE_API_KEY bulunamadÄ±. Uygulama durduruluyor.")
    st.stop()

try:
    genai.configure(api_key=GOOGLE_API_KEY)
    logger.info("Google API AnahtarÄ± baÅŸarÄ±yla yapÄ±landÄ±rÄ±ldÄ±.")
except Exception as e:
    logger.error(f"Genel API YapÄ±landÄ±rma HatasÄ±: {e}")
    st.error(f"API anahtarÄ± yapÄ±landÄ±rÄ±lamadÄ±: {e}. LÃ¼tfen anahtarÄ±nÄ±zÄ± kontrol edin.")
    st.stop()


# Gemini Model Parametreleri (Global olarak tanÄ±mlandÄ±)
GLOBAL_MODEL_NAME = 'gemini-1.5-flash-latest'
GLOBAL_TEMPERATURE = 0.7
GLOBAL_TOP_P = 0.95
GLOBAL_TOP_K = 40
GLOBAL_MAX_OUTPUT_TOKENS = 4096

# --- YardÄ±mcÄ± Fonksiyonlar (Helper Functions) ---

def initialize_gemini_model():
    """Gemini modelini baÅŸlatÄ±r ve oturum durumuna kaydeder."""
    if "gemini_model" not in st.session_state:
        st.session_state.gemini_model = None # BaÅŸlangÄ±Ã§ta None olarak ayarla
    
    if st.session_state.gemini_model is None:
        try:
            st.session_state.gemini_model = genai.GenerativeModel(
                model_name=GLOBAL_MODEL_NAME,
                generation_config=genai.GenerationConfig(
                    temperature=GLOBAL_TEMPERATURE,
                    top_p=GLOBAL_TOP_P,
                    top_k=GLOBAL_TOP_K,
                    max_output_tokens=GLOBAL_MAX_OUTPUT_TOKENS,
                )
            )
            st.session_state.models_initialized = True
            st.toast("Gemini Modeli baÅŸarÄ±yla baÅŸlatÄ±ldÄ±!", icon="âœ…")
            logger.info(f"Gemini Modeli baÅŸlatÄ±ldÄ±: {GLOBAL_MODEL_NAME}")
        except Exception as e:
            st.error(f"Gemini modelini baÅŸlatÄ±rken bir hata oluÅŸtu: {e}. LÃ¼tfen API anahtarÄ±nÄ±zÄ±n doÄŸru ve aktif olduÄŸundan emin olun.")
            st.session_state.models_initialized = False
            logger.error(f"Gemini modeli baÅŸlatma hatasÄ±: {e}")

def add_to_chat_history(chat_id, role, content):
    """Sohbet geÃ§miÅŸine mesaj ekler."""
    if chat_id not in st.session_state.all_chats:
        st.session_state.all_chats[chat_id] = []
    
    # EÄŸer iÃ§erik bir PIL Image nesnesi ise, byte'a dÃ¶nÃ¼ÅŸtÃ¼rerek kaydet
    if isinstance(content, Image.Image):
        img_byte_arr = io.BytesIO()
        content.save(img_byte_arr, format='PNG') # PNG daha iyi ÅŸeffaflÄ±k/kalite sunar, JPEG de olabilir
        st.session_state.all_chats[chat_id].append({"role": role, "parts": [img_byte_arr.getvalue()]})
    elif isinstance(content, bytes): # EÄŸer zaten bytes ise doÄŸrudan ekle
        st.session_state.all_chats[chat_id].append({"role": role, "parts": [content]})
    else: # Metin ise
        st.session_state.all_chats[chat_id].append({"role": role, "parts": [content]})
    
    # Sohbet geÃ§miÅŸini gÃ¼ncelledikten sonra logla
    logger.info(f"Sohbet geÃ§miÅŸine eklendi: Chat ID: {chat_id}, Rol: {role}, Ä°Ã§erik TÃ¼rÃ¼: {type(content)}")


def load_chat_history():
    """Sohbet geÃ§miÅŸini yÃ¼kler (uygulama baÅŸlatÄ±ldÄ±ÄŸÄ±nda veya yeniden yÃ¼klendiÄŸinde)."""
    if "all_chats" not in st.session_state:
        st.session_state.all_chats = {}
        logger.info("all_chats oturum durumu baÅŸlatÄ±ldÄ±.")
    if "active_chat_id" not in st.session_state:
        # Tek sohbet modu iÃ§in varsayÄ±lan olarak 'chat_0'
        st.session_state.active_chat_id = "chat_0"
        logger.info("active_chat_id varsayÄ±lan olarak 'chat_0' olarak ayarlandÄ±.")
    
    # Mevcut aktif sohbetin boÅŸ olduÄŸundan emin ol
    if st.session_state.active_chat_id not in st.session_state.all_chats:
        st.session_state.all_chats[st.session_state.active_chat_id] = []
        logger.info(f"Aktif sohbet ID'si {st.session_state.active_chat_id} iÃ§in boÅŸ bir liste oluÅŸturuldu.")

def clear_active_chat():
    """Aktif sohbetin iÃ§eriÄŸini temizler."""
    if st.session_state.active_chat_id in st.session_state.all_chats:
        st.session_state.all_chats[st.session_state.active_chat_id] = []
        # Chat session'Ä± da temizle, aksi takdirde eski geÃ§miÅŸi hatÄ±rlayabilir
        if "chat_session" in st.session_state:
            del st.session_state.chat_session
        st.toast("Aktif sohbet temizlendi!", icon="ğŸ§¹")
        logger.info(f"Aktif sohbet ({st.session_state.active_chat_id}) temizlendi.")
    st.rerun()

def text_to_speech(text):
    """Metni konuÅŸmaya Ã§evirir ve sesi oynatÄ±r."""
    if not TTS_SR_AVAILABLE:
        st.warning("Metin okuma Ã¶zelliÄŸi kullanÄ±lamÄ±yor (pyttsx3 yÃ¼klÃ¼ deÄŸil).")
        return False
    try:
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        found_turkish_voice = False
        for voice in voices:
            if "turkish" in voice.name.lower() or "tr-tr" in voice.id.lower():
                engine.setProperty('voice', voice.id)
                found_turkish_voice = True
                logger.info(f"TÃ¼rkÃ§e ses bulundu ve ayarlandÄ±: {voice.name}")
                break
        if not found_turkish_voice:
            logger.warning("TÃ¼rkÃ§e ses bulunamadÄ±, varsayÄ±lan ses kullanÄ±lacak.")
            st.warning("TÃ¼rkÃ§e ses bulunamadÄ±, varsayÄ±lan ses kullanÄ±lacak. Ä°ÅŸletim sisteminizin ses ayarlarÄ±nÄ± kontrol ediniz.")

        engine.say(text)
        engine.runAndWait()
        logger.info("Metinden sese Ã§evirme baÅŸarÄ±lÄ±.")
        return True
    except Exception as e:
        st.error(f"Metni sese Ã§evirirken hata oluÅŸtu: {e}")
        logger.error(f"Metinden sese Ã§evirme hatasÄ±: {e}")
        return False

def record_audio():
    """KullanÄ±cÄ±dan ses giriÅŸi alÄ±r."""
    if not TTS_SR_AVAILABLE:
        st.warning("Ses tanÄ±ma Ã¶zelliÄŸi kullanÄ±lamÄ±yor (speech_recognition yÃ¼klÃ¼ deÄŸil).")
        return ""
    r = sr.Recognizer()
    with sr.Microphone() as source:
        st.write("Dinleniyor...")
        logger.info("Mikrofondan dinleniyor...")
        try:
            audio = r.listen(source, timeout=5, phrase_time_limit=10)
            logger.info("Ses kaydÄ± tamamlandÄ±.")
        except sr.WaitTimeoutError:
            st.warning("Ses algÄ±lanamadÄ±, lÃ¼tfen tekrar deneyin.")
            logger.warning("Ses algÄ±lama zaman aÅŸÄ±mÄ±na uÄŸradÄ±.")
            return ""
        except Exception as e:
            st.error(f"Ses kaydÄ± sÄ±rasÄ±nda bir hata oluÅŸtu: {e}")
            logger.error(f"Ses kaydÄ± hatasÄ±: {e}")
            return ""
            
    try:
        text = r.recognize_google(audio, language="tr-TR")
        st.write(f"Sen dedin: {text}")
        logger.info(f"TanÄ±nan ses: {text}")
        return text
    except sr.UnknownValueError:
        st.warning("Ne dediÄŸini anlayamadÄ±m.")
        logger.warning("Google Speech Recognition anlaÅŸÄ±lamayan ses.")
        return ""
    except sr.RequestError as e:
        st.error(f"Ses tanÄ±ma servisine ulaÅŸÄ±lamÄ±yor; {e}")
        logger.error(f"Google Speech Recognition API hatasÄ±: {e}")
        return ""
    except Exception as e:
        st.error(f"Ses tanÄ±ma sÄ±rasÄ±nda beklenmeyen bir hata oluÅŸtu: {e}")
        logger.error(f"Genel ses tanÄ±ma hatasÄ±: {e}")
        return ""

@st.cache_data(ttl=3600) # Bir saat Ã¶nbelleÄŸe al
def duckduckgo_search(query):
    """DuckDuckGo kullanarak web aramasÄ± yapar."""
    logger.info(f"DuckDuckGo aramasÄ± baÅŸlatÄ±lÄ±yor: {query}")
    try:
        with DDGS() as ddgs:
            results = [r for r in ddgs.text(query, max_results=5)]
            logger.info(f"DuckDuckGo aramasÄ± tamamlandÄ±, {len(results)} sonuÃ§ bulundu.")
            return results
    except Exception as e:
        st.error(f"DuckDuckGo aramasÄ± yapÄ±lÄ±rken hata oluÅŸtu: {e}")
        logger.error(f"DuckDuckGo arama hatasÄ±: {e}")
        return []

@st.cache_data(ttl=3600) # Bir saat Ã¶nbelleÄŸe al
def wikipedia_search(query):
    """Wikipedia'da arama yapar."""
    logger.info(f"Wikipedia aramasÄ± baÅŸlatÄ±lÄ±yor: {query}")
    try:
        response = requests.get(f"https://en.wikipedia.org/w/api.php?action=query&list=search&srsearch={query}&format=json")
        response.raise_for_status() # HTTP hatalarÄ±nÄ± yakala
        data = response.json()
        if data and "query" in data and "search" in data["query"]:
            logger.info(f"Wikipedia aramasÄ± tamamlandÄ±, {len(data['query']['search'])} sonuÃ§ bulundu.")
            return data["query"]["search"]
        logger.info("Wikipedia aramasÄ± sonuÃ§ bulamadÄ±.")
        return []
    except requests.exceptions.RequestException as e:
        st.error(f"Wikipedia aramasÄ± yapÄ±lÄ±rken aÄŸ hatasÄ± oluÅŸtu: {e}")
        logger.error(f"Wikipedia aÄŸ hatasÄ±: {e}")
        return []
    except json.JSONDecodeError as e:
        st.error(f"Wikipedia yanÄ±tÄ± Ã§Ã¶zÃ¼mlenirken hata oluÅŸtu: {e}")
        logger.error(f"Wikipedia JSON Ã§Ã¶zÃ¼mleme hatasÄ±: {e}")
        return []
    except Exception as e:
        st.error(f"Wikipedia aramasÄ± yapÄ±lÄ±rken genel bir hata oluÅŸtu: {e}")
        logger.error(f"Wikipedia genel arama hatasÄ±: {e}")
        return []

def generate_image(prompt):
    """GÃ¶rsel oluÅŸturma (Ã¶rnek - placeholder)."""
    st.warning("GÃ¶rsel oluÅŸturma Ã¶zelliÄŸi ÅŸu anda bir placeholder'dÄ±r ve gerÃ§ek bir API'ye baÄŸlÄ± deÄŸildir.")
    placeholder_image_url = "https://via.placeholder.com/400x300.png?text=GÃ¶rsel+OluÅŸturuldu"
    st.image(placeholder_image_url, caption=prompt)
    add_to_chat_history(st.session_state.active_chat_id, "model", f"'{prompt}' iÃ§in bir gÃ¶rsel oluÅŸturuldu (Ã¶rnek).")
    logger.info(f"GÃ¶rsel oluÅŸturma placeholder'Ä± kullanÄ±ldÄ±: {prompt}")

def process_image_input(uploaded_file):
    """YÃ¼klenen gÃ¶rseli iÅŸler ve metne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
    if uploaded_file is not None:
        try:
            image = Image.open(uploaded_file)
            st.image(image, caption="YÃ¼klenen GÃ¶rsel", use_column_width=True)
            logger.info(f"GÃ¶rsel yÃ¼klendi: {uploaded_file.name}")

            # GÃ¶rseli sohbet geÃ§miÅŸine ekle
            add_to_chat_history(st.session_state.active_chat_id, "user", image) # Image nesnesini doÄŸrudan ekle
            
            # Gemini modelinin Ã§ok modlu yeteneklerini kullanarak gÃ¶rseli anlama
            if st.session_state.gemini_model:
                # Yeni bir chat session baÅŸlat, sadece gÃ¶rsel aÃ§Ä±klama iÃ§in
                # Bu kÄ±sÄ±m stream=True kullanmaz, tek bir yanÄ±t beklenir
                vision_chat_session = st.session_state.gemini_model.start_chat(history=[])
                
                # Modeli hem gÃ¶rseli hem de metni kullanarak sorgula
                response = vision_chat_session.send_message([image, "Bu gÃ¶rselde ne gÃ¶rÃ¼yorsun?"])
                
                response_text = response.text
                st.markdown(response_text)
                
                add_to_chat_history(st.session_state.active_chat_id, "model", response_text)
                logger.info("GÃ¶rsel aÃ§Ä±klamasÄ± Gemini modeli tarafÄ±ndan iÅŸlendi.")
            else:
                st.error("Gemini modeli baÅŸlatÄ±lmamÄ±ÅŸ.")
                logger.error("GÃ¶rsel iÅŸleme sÄ±rasÄ±nda Gemini modeli baÅŸlatÄ±lmamÄ±ÅŸ.")
        except Exception as e:
            st.error(f"GÃ¶rsel iÅŸlenirken bir hata oluÅŸtu: {e}")
            logger.error(f"GÃ¶rsel iÅŸleme hatasÄ±: {e}")

# --- UI Components (KullanÄ±cÄ± ArayÃ¼zÃ¼ BileÅŸenleri) ---

def display_about_section():
    """'HakkÄ±nda' bÃ¶lÃ¼mÃ¼nÃ¼ gÃ¶sterir."""
    st.sidebar.markdown("---")
    st.sidebar.markdown("## HakkÄ±nda")
    st.sidebar.markdown("""
        **Hanogt AI v5.1.5 Pro+ Enhanced (Refactored)**
        Streamlit ve Google Gemini Pro ile geliÅŸtirilmiÅŸtir.

        **Desteklenen Ã–zellikler:**
        * **Genel sohbet**
        * **Web aramasÄ±** (DuckDuckGo, Wikipedia)
        * **Bilgi tabanÄ±** yanÄ±tlarÄ±
        * **YaratÄ±cÄ± metin** Ã¼retimi
        * **Basit gÃ¶rsel** oluÅŸturma (Ã¶rnek)
        * **Metin okuma** (TTS)
        * **Geri bildirim** mekanizmasÄ±
        (Supabase) Â© 2025
    """)

def display_settings_section():
    """Ayarlar bÃ¶lÃ¼mÃ¼nÃ¼ gÃ¶sterir."""
    st.sidebar.markdown("---")
    st.sidebar.markdown("## Ayarlar")

    if st.button("ğŸ§¹ Sohbet GeÃ§miÅŸini Temizle", key="clear_chat_button"):
        clear_active_chat()

def display_main_chat_interface():
    """Ana sohbet arayÃ¼zÃ¼nÃ¼ gÃ¶sterir."""
    st.markdown("## Uygulama Modu")

    st.session_state.chat_mode = st.radio(
        "Mod SeÃ§imi",
        ["YazÄ±lÄ± Sohbet", "GÃ¶rsel OluÅŸturucu", "Sesli Sohbet (Dosya YÃ¼kle)", "YaratÄ±cÄ± StÃ¼dyo"],
        horizontal=True,
        index=st.session_state.get("current_mode_index", 0),
        key="main_mode_radio"
    )
    st.session_state.current_mode_index = ["YazÄ±lÄ± Sohbet", "GÃ¶rsel OluÅŸturucu", "Sesli Sohbet (Dosya YÃ¼kle)", "YaratÄ±cÄ± StÃ¼dyo"].index(st.session_state.chat_mode)


    if st.session_state.chat_mode == "YazÄ±lÄ± Sohbet":
        handle_text_chat()
    elif st.session_state.chat_mode == "GÃ¶rsel OluÅŸturucu":
        handle_image_generation()
    elif st.session_state.chat_mode == "Sesli Sohbet (Dosya YÃ¼kle)":
        handle_voice_chat()
    elif st.session_state.chat_mode == "YaratÄ±cÄ± StÃ¼dyo":
        handle_creative_studio()

def handle_text_chat():
    """YazÄ±lÄ± sohbet modunu yÃ¶netir."""
    chat_messages = st.session_state.all_chats.get(st.session_state.active_chat_id, [])

    for message_index, message in enumerate(chat_messages):
        with st.chat_message(message["role"]):
            content_part = message["parts"][0]
            if isinstance(content_part, str):
                st.markdown(content_part)
            elif isinstance(content_part, bytes): # GÃ¶rsel ise
                try:
                    image = Image.open(io.BytesIO(content_part))
                    st.image(image, caption="YÃ¼klenen GÃ¶rsel", use_column_width=True)
                except Exception as e:
                    st.warning(f"GÃ¶rsel yÃ¼klenemedi: {e}")
                    logger.warning(f"GÃ¶rsel yÃ¼kleme hatasÄ± ({message_index}): {e}")

            col_btn1, col_btn2 = st.columns([0.05, 1])
            with col_btn1:
                if st.button("â–¶ï¸", key=f"tts_btn_{st.session_state.active_chat_id}_{message_index}"):
                    if isinstance(content_part, str):
                        text_to_speech(content_part)
                    else:
                        st.warning("Bu iÃ§erik konuÅŸmaya Ã§evrilemez (metin deÄŸil).")
            with col_btn2:
                if st.button("ğŸ‘", key=f"fb_btn_{st.session_state.active_chat_id}_{message_index}"):
                    st.toast("Geri bildirim iÃ§in teÅŸekkÃ¼rler!", icon="ğŸ™")
                    logger.info(f"Geri bildirim alÄ±ndÄ±. Mesaj Index: {message_index}")


    prompt = st.chat_input("MesajÄ±nÄ±zÄ± yazÄ±n veya bir komut girin: Ã–rn: 'Merhaba', 'web ara: Streamlit', 'yaratÄ±cÄ± metin: uzaylÄ±lar'...")

    if prompt:
        add_to_chat_history(st.session_state.active_chat_id, "user", prompt)
        logger.info(f"KullanÄ±cÄ± promptu: {prompt}")

        if prompt.lower().startswith("web ara:"):
            query = prompt[len("web ara:"):].strip()
            results = duckduckgo_search(query)
            if results:
                response_text = "Web Arama SonuÃ§larÄ±:\n"
                for i, r in enumerate(results):
                    response_text += f"{i+1}. **{r['title']}**\n{r['body']}\n{r['href']}\n\n"
            else:
                response_text = "AradÄ±ÄŸÄ±nÄ±z terimle ilgili sonuÃ§ bulunamadÄ±."
            add_to_chat_history(st.session_state.active_chat_id, "model", response_text)
            logger.info(f"Web aramasÄ± tamamlandÄ±. SonuÃ§: {response_text[:100]}...")
        elif prompt.lower().startswith("wiki ara:"):
            query = prompt[len("wiki ara:"):].strip()
            results = wikipedia_search(query)
            if results:
                response_text = "Wikipedia Arama SonuÃ§larÄ±:\n"
                for i, r in enumerate(results):
                    response_text += f"{i+1}. **{r['title']}**\n"
            else:
                response_text = "AradÄ±ÄŸÄ±nÄ±z terimle ilgili sonuÃ§ bulunamadÄ±."
            add_to_chat_history(st.session_state.active_chat_id, "model", response_text)
            logger.info(f"Wikipedia aramasÄ± tamamlandÄ±. SonuÃ§: {response_text[:100]}...")
        elif prompt.lower().startswith("gÃ¶rsel oluÅŸtur:"):
            image_prompt = prompt[len("gÃ¶rsel oluÅŸtur:"):].strip()
            generate_image(image_prompt)
        else:
            if st.session_state.gemini_model:
                with st.spinner("YanÄ±t oluÅŸturuluyor..."):
                    try:
                        # Chat session'Ä± sadece ihtiyaÃ§ duyulduÄŸunda baÅŸlat veya gÃ¼ncelleyin
                        if "chat_session" not in st.session_state or \
                           (st.session_state.chat_session.history != st.session_state.all_chats[st.session_state.active_chat_id] and \
                            st.session_state.all_chats[st.session_state.active_chat_id]): # GeÃ§miÅŸ boÅŸsa yeniden baÅŸlatma
                            
                            # GeÃ§miÅŸte gÃ¶rsel olup olmadÄ±ÄŸÄ±nÄ± kontrol et (Gemini modeli sadece metin ve gÃ¶rseli birlikte alÄ±r, sadece bytes'Ä± almaz)
                            # `add_to_chat_history` Image nesnesini bytes'a Ã§eviriyor, bu yÃ¼zden kontrol etmemiz gerekiyor.
                            processed_history = []
                            for msg in st.session_state.all_chats[st.session_state.active_chat_id]:
                                if msg["role"] == "user" and isinstance(msg["parts"][0], bytes):
                                    try:
                                        # Bytes'Ä± tekrar PIL Image'a dÃ¶nÃ¼ÅŸtÃ¼rerek modele gÃ¶nder
                                        processed_history.append({"role": msg["role"], "parts": [Image.open(io.BytesIO(msg["parts"][0]))]})
                                    except Exception as e:
                                        logger.warning(f"GeÃ§miÅŸteki gÃ¶rsel yÃ¼klenemedi, atlanÄ±yor: {e}")
                                        # GÃ¶rsel yÃ¼klenemezse veya geÃ§ersizse, bu mesajÄ± atlayabiliriz
                                        continue 
                                else:
                                    processed_history.append(msg)

                            st.session_state.chat_session = st.session_state.gemini_model.start_chat(
                                history=processed_history
                            )
                            logger.info("Yeni Gemini sohbet oturumu baÅŸlatÄ±ldÄ± veya gÃ¼ncellendi.")

                        # KullanÄ±cÄ±nÄ±n son mesajÄ±nÄ± gÃ¶nder (yukarÄ±da zaten geÃ§miÅŸe eklendi)
                        response = st.session_state.chat_session.send_message(prompt, stream=True)
                        
                        response_text = ""
                        response_placeholder = st.empty() 
                        for chunk in response:
                            response_text += chunk.text
                            with response_placeholder.container():
                                st.markdown(response_text)
                        
                        add_to_chat_history(st.session_state.active_chat_id, "model", response_text)
                        logger.info("Gemini yanÄ±tÄ± baÅŸarÄ±yla alÄ±ndÄ± ve eklendi.")

                    except Exception as e:
                        st.error(f"YanÄ±t alÄ±nÄ±rken beklenmeyen bir hata oluÅŸtu: {e}")
                        st.error(f"Kaynak: Hata ({e})")
                        logger.error(f"Gemini yanÄ±tÄ± hatasÄ±: {e}")
            else:
                st.warning("Gemini modeli baÅŸlatÄ±lmamÄ±ÅŸ. LÃ¼tfen API anahtarÄ±nÄ±zÄ± kontrol edin.")
                logger.warning("Gemini modeli baÅŸlatÄ±lmamÄ±ÅŸ uyarÄ±sÄ±.")
        
        st.rerun()

def handle_image_generation():
    """GÃ¶rsel oluÅŸturma modunu yÃ¶netir."""
    st.subheader("GÃ¶rsel OluÅŸturucu")
    image_prompt = st.text_input("OluÅŸturmak istediÄŸiniz gÃ¶rseli tanÄ±mlayÄ±n:", key="image_prompt_input")
    if st.button("GÃ¶rsel OluÅŸtur", key="generate_image_button"):
        if image_prompt:
            generate_image(image_prompt)
        else:
            st.warning("LÃ¼tfen bir gÃ¶rsel aÃ§Ä±klamasÄ± girin.")
            logger.warning("GÃ¶rsel oluÅŸturma iÃ§in prompt girilmedi.")

def handle_voice_chat():
    """Sesli sohbet modunu yÃ¶netir."""
    st.subheader("Sesli Sohbet")
    
    if not TTS_SR_AVAILABLE:
        st.info("Sesli sohbet Ã¶zellikleri kullanÄ±lamÄ±yor. Gerekli kÃ¼tÃ¼phanelerin (pyttsx3, SpeechRecognition) kurulu olduÄŸundan emin olun.")
    else:
        uploaded_audio_file = st.file_uploader("Ses dosyasÄ± yÃ¼kle (MP3, WAV)", type=["mp3", "wav"], key="audio_uploader")
        if uploaded_audio_file:
            st.audio(uploaded_audio_file, format=uploaded_audio_file.type)
            st.warning("Ses dosyasÄ±ndan metin transkripsiyonu Ã¶zelliÄŸi ÅŸu anda bir placeholder'dÄ±r.")
            logger.info(f"Ses dosyasÄ± yÃ¼klendi: {uploaded_audio_file.name}")

        st.markdown("---")
        st.subheader("CanlÄ± Ses GiriÅŸi")
        if st.button("Mikrofonu BaÅŸlat", key="start_mic_button"):
            recognized_text = record_audio()
            if recognized_text:
                add_to_chat_history(st.session_state.active_chat_id, "user", recognized_text)
                logger.info(f"CanlÄ± ses giriÅŸi tanÄ±ndÄ±: {recognized_text}")

                if st.session_state.gemini_model:
                    with st.spinner("YanÄ±t oluÅŸturuluyor..."):
                        try:
                            # Sohbet oturumunu gÃ¼ncelle veya baÅŸlat
                            processed_history = []
                            for msg in st.session_state.all_chats[st.session_state.active_chat_id]:
                                if msg["role"] == "user" and isinstance(msg["parts"][0], bytes):
                                    try:
                                        processed_history.append({"role": msg["role"], "parts": [Image.open(io.BytesIO(msg["parts"][0]))]})
                                    except Exception as e:
                                        logger.warning(f"GeÃ§miÅŸteki gÃ¶rsel yÃ¼klenemedi (sesli sohbet), atlanÄ±yor: {e}")
                                        continue 
                                else:
                                    processed_history.append(msg)

                            st.session_state.chat_session = st.session_state.gemini_model.start_chat(
                                history=processed_history
                            )
                            
                            response = st.session_state.chat_session.send_message(recognized_text, stream=True)
                            response_text = ""
                            response_placeholder = st.empty()
                            for chunk in response:
                                response_text += chunk.text
                                with response_placeholder.container():
                                    st.markdown(response_text)
                            
                            add_to_chat_history(st.session_state.active_chat_id, "model", response_text)
                            text_to_speech(response_text)
                            logger.info("CanlÄ± ses giriÅŸi iÃ§in Gemini yanÄ±tÄ± oluÅŸturuldu ve okundu.")
                            st.rerun()

                        except Exception as e:
                            st.error(f"YanÄ±t alÄ±nÄ±rken beklenmeyen bir hata oluÅŸtu: {e}")
                            st.error(f"Kaynak: Hata ({e})")
                            logger.error(f"CanlÄ± ses yanÄ±tÄ± hatasÄ±: {e}")
                else:
                    st.warning("Gemini modeli baÅŸlatÄ±lmamÄ±ÅŸ.")
                    logger.warning("CanlÄ± ses giriÅŸi sÄ±rasÄ±nda Gemini modeli baÅŸlatÄ±lmamÄ±ÅŸ.")

def handle_creative_studio():
    """YaratÄ±cÄ± stÃ¼dyo modunu yÃ¶netir."""
    st.subheader("YaratÄ±cÄ± StÃ¼dyo")
    st.write("Bu bÃ¶lÃ¼m, yaratÄ±cÄ± metin Ã¼retimi gibi geliÅŸmiÅŸ Ã¶zellikler iÃ§in tasarlanmÄ±ÅŸtÄ±r.")
    
    creative_prompt = st.text_area("YaratÄ±cÄ± metin isteÄŸinizi girin:", height=150, key="creative_prompt_input")
    if st.button("Metin OluÅŸtur", key="generate_creative_text_button"):
        if creative_prompt:
            if st.session_state.gemini_model:
                with st.spinner("YaratÄ±cÄ± metin oluÅŸturuluyor..."):
                    try:
                        # YaratÄ±cÄ± metin iÃ§in yeni bir sohbet oturumu baÅŸlat, geÃ§miÅŸi sÄ±fÄ±rla
                        creative_chat_session = st.session_state.gemini_model.start_chat(history=[])
                        response = creative_chat_session.send_message(f"YaratÄ±cÄ± metin oluÅŸtur: {creative_prompt}", stream=True)
                        
                        response_text = ""
                        response_placeholder = st.empty()
                        for chunk in response:
                            response_text += chunk.text
                            with response_placeholder.container():
                                st.markdown(response_text)
                        
                        add_to_chat_history(st.session_state.active_chat_id, "model", f"YaratÄ±cÄ± Metin OluÅŸturuldu: {response_text}")
                        logger.info("YaratÄ±cÄ± metin baÅŸarÄ±yla oluÅŸturuldu ve eklendi.")

                    except Exception as e:
                        st.error(f"YaratÄ±cÄ± metin oluÅŸturulurken bir hata oluÅŸtu: {e}")
                        st.error(f"Kaynak: Hata ({e})")
                        logger.error(f"YaratÄ±cÄ± metin oluÅŸturma hatasÄ±: {e}")
            else:
                st.warning("Gemini modeli baÅŸlatÄ±lmamÄ±ÅŸ.")
                logger.warning("YaratÄ±cÄ± stÃ¼dyo sÄ±rasÄ±nda Gemini modeli baÅŸlatÄ±lmamÄ±ÅŸ.")
        else:
            st.warning("LÃ¼tfen bir yaratÄ±cÄ± metin isteÄŸi girin.")
            logger.warning("YaratÄ±cÄ± metin oluÅŸturma iÃ§in prompt girilmedi.")


# --- Main Application Logic (Ana Uygulama MantÄ±ÄŸÄ±) ---

def main():
    """Ana Streamlit uygulamasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±r."""
    st.set_page_config(
        page_title="Hanogt AI Asistan",
        page_icon="âœ¨",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # Oturum durumu deÄŸiÅŸkenlerini baÅŸlat
    if "models_initialized" not in st.session_state:
        st.session_state.models_initialized = False
        logger.info("models_initialized oturum durumu baÅŸlatÄ±ldÄ±.")
    
    load_chat_history()
    initialize_gemini_model() # Modeli burada baÅŸlat

    display_about_section()
    display_settings_section()
    display_main_chat_interface()

    # Footer
    st.sidebar.markdown("---")
    st.sidebar.markdown(f"""
        <div style="text-align: center; font-size: 12px; color: gray;">
            KullanÄ±cÄ±: OÄŸuz Han GÃ¼lÃ¼zade <br>
            Hanogt AI v5.1.5 Pro+ Enhanced (Refactored) Â© {datetime.datetime.now().year} <br>
            AI: Aktif ({GLOBAL_MODEL_NAME}) | Log: Aktif
        </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()

