# app.py

# --- Gerekli KÃ¼tÃ¼phaneler ---
# Temel Streamlit ve Veri Ä°ÅŸleme
import streamlit as st
import requests # pip install requests
from bs4 import BeautifulSoup # pip install beautifulsoup4 lxml
import json
import re
import os
import random
import time
from io import BytesIO
from urllib.parse import urlparse, unquote
from datetime import datetime
import uuid

# Yapay Zeka ve Arama MotorlarÄ±
import wikipedia # pip install wikipedia
from duckduckgo_search import DDGS # pip install -U duckduckgo_search
import google.generativeai as genai # pip install google-generativeai

# Multimedya ve DiÄŸerleri
from PIL import Image, ImageDraw, ImageFont # pip install Pillow
import speech_recognition as sr # pip install SpeechRecognition pydub
#   -> Gerekirse: sudo apt-get install ffmpeg veya brew install ffmpeg
import pyttsx3 # pip install pyttsx3
#   -> Linux iÃ§in: sudo apt-get update && sudo apt-get install espeak ffmpeg libespeak1

# Supabase (isteÄŸe baÄŸlÄ±, loglama/feedback iÃ§in)
try:
    from supabase import create_client, Client # pip install supabase
    from postgrest import APIError as SupabaseAPIError
except ImportError:
    st.toast("Supabase kÃ¼tÃ¼phanesi bulunamadÄ±. Loglama/Feedback devre dÄ±ÅŸÄ±.", icon="â„¹ï¸")
    create_client = None
    Client = None
    SupabaseAPIError = None

# --- Sayfa YapÄ±landÄ±rmasÄ± ---
st.set_page_config(
    page_title="Hanogt AI Pro+",
    page_icon="ğŸŒŸ",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- Sabitler ve YapÄ±landÄ±rma ---
APP_NAME = "Hanogt AI"
APP_VERSION = "5.0.1 Pro+ Stable" # SÃ¼rÃ¼m gÃ¼ncellendi (Hata dÃ¼zeltmeleri)
CURRENT_YEAR = datetime.now().year
CHAT_HISTORY_FILE = "chat_history_v2.json"
KNOWLEDGE_BASE_FILE = "knowledge_base.json"
DEFAULT_ERROR_MESSAGE = "ÃœzgÃ¼nÃ¼m, bir sorun oluÅŸtu. LÃ¼tfen tekrar deneyin."
REQUEST_TIMEOUT = 20
SCRAPE_MAX_CHARS = 3500
GEMINI_ERROR_PREFIX = "GeminiError:"
USER_AGENT = f"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36 {APP_NAME}/{APP_VERSION}" # GÃ¼ncel User Agent
SUPABASE_TABLE_LOGS = "chat_logs"
SUPABASE_TABLE_FEEDBACK = "user_feedback"
FONT_FILE = "arial.ttf" # Mevcutsa kullanÄ±lacak font

# --- Dinamik Fonksiyonlar ---
DYNAMIC_FUNCTIONS_MAP = {
    "saat kaÃ§": lambda: f"Åu an saat: {datetime.now().strftime('%H:%M:%S')}",
    "bugÃ¼n ayÄ±n kaÃ§Ä±": lambda: f"BugÃ¼n {datetime.now().strftime('%d %B %Y, %A')} ({datetime.now().year})",
    "tarih ne": lambda: f"BugÃ¼n {datetime.now().strftime('%d %B %Y, %A')} ({datetime.now().year})"
}

# --- Bilgi TabanÄ± ---
knowledge_base_load_error = None

@st.cache_data(ttl=3600)
def load_knowledge_from_file(filename=KNOWLEDGE_BASE_FILE, user_name_for_greeting="kullanÄ±cÄ±"):
    """Bilgi tabanÄ±nÄ± dosyadan yÃ¼kler veya varsayÄ±lanÄ± kullanÄ±r."""
    global knowledge_base_load_error
    default_knowledge = {
        "merhaba": [f"Merhaba {user_name_for_greeting}!", "Selam!", "HoÅŸ geldin!", "Size nasÄ±l yardÄ±mcÄ± olabilirim?"],
        "selam": ["Merhaba!", "Selam sana da!", "NasÄ±l gidiyor?"],
        "nasÄ±lsÄ±n": ["Ä°yiyim, teÅŸekkÃ¼rler! Siz nasÄ±lsÄ±nÄ±z?", "Harika hissediyorum!", "Sizin iÃ§in ne yapabilirim?"],
        "hanogt kimdir": [f"Ben {APP_NAME} ({APP_VERSION}), Streamlit ve Python ile geliÅŸtirilmiÅŸ bir AI asistanÄ±yÄ±m.", f"{APP_NAME}, sorularÄ±nÄ±zÄ± yanÄ±tlamak, metin Ã¼retmek ve basit gÃ¶rseller oluÅŸturmak iÃ§in tasarlandÄ±."],
        "teÅŸekkÃ¼r ederim": ["Rica ederim!", "Ne demek!", "YardÄ±mcÄ± olabildiÄŸime sevindim.", "Her zaman!"],
        "gÃ¶rÃ¼ÅŸÃ¼rÃ¼z": ["GÃ¶rÃ¼ÅŸmek Ã¼zere!", "HoÅŸÃ§a kal!", "Ä°yi gÃ¼nler!", "Tekrar beklerim!"],
        "adÄ±n ne": [f"Ben {APP_NAME}, versiyon {APP_VERSION}.", f"Bana {APP_NAME} diyebilirsiniz."],
        "ne yapabilirsin": ["SorularÄ±nÄ±zÄ± yanÄ±tlayabilir, web'de arama yapabilir, yaratÄ±cÄ± metinler Ã¼retebilir ve basit gÃ¶rseller Ã§izebilirim.", "Size Ã§eÅŸitli konularda yardÄ±mcÄ± olabilirim."],
        "saat kaÃ§": ["Saat bilgisini alÄ±yorum."], "bugÃ¼n ayÄ±n kaÃ§Ä±": ["Tarih bilgisini alÄ±yorum."], "tarih ne": ["Tarih bilgisini alÄ±yorum."],
        "hava durumu": ["ÃœzgÃ¼nÃ¼m, gÃ¼ncel hava durumu bilgisi saÄŸlayamÄ±yorum.", "Hava durumu servisim henÃ¼z aktif deÄŸil."]
    }
    try:
        if os.path.exists(filename):
            with open(filename, "r", encoding="utf-8") as f: loaded_kb = json.load(f)
            merged_kb = {**default_knowledge, **loaded_kb}
            knowledge_base_load_error = None
            return merged_kb
        else:
            knowledge_base_load_error = f"Bilgi tabanÄ± ({filename}) bulunamadÄ±. VarsayÄ±lan kullanÄ±lÄ±yor."
            st.toast(knowledge_base_load_error, icon="â„¹ï¸")
            return default_knowledge
    except json.JSONDecodeError:
        knowledge_base_load_error = f"Bilgi tabanÄ± ({filename}) hatalÄ±. VarsayÄ±lan kullanÄ±lÄ±yor."
        st.toast(knowledge_base_load_error, icon="âš ï¸")
        return default_knowledge
    except Exception as e:
        knowledge_base_load_error = f"Bilgi tabanÄ± yÃ¼klenirken hata: {e}. VarsayÄ±lan kullanÄ±lÄ±yor."
        st.toast(knowledge_base_load_error, icon="ğŸ”¥")
        return default_knowledge

def kb_chatbot_response(query, knowledge_base_dict):
    """Bilgi tabanÄ±ndan veya dinamik fonksiyonlardan yanÄ±t dÃ¶ndÃ¼rÃ¼r."""
    query_lower = query.lower().strip()
    # 1. Dinamik Fonksiyon
    if query_lower in DYNAMIC_FUNCTIONS_MAP:
        try: return DYNAMIC_FUNCTIONS_MAP[query_lower]()
        except Exception as e: st.error(f"Fonksiyon hatasÄ± ({query_lower}): {e}"); return DEFAULT_ERROR_MESSAGE
    # 2. Tam EÅŸleÅŸme
    if query_lower in knowledge_base_dict:
        resp = knowledge_base_dict[query_lower]
        return random.choice(resp) if isinstance(resp, list) else resp
    # 3. KÄ±smi EÅŸleÅŸme (Ä°Ã§erme)
    partial_matches = [resp for key, resp_list in knowledge_base_dict.items() if key in query_lower for resp in (resp_list if isinstance(resp_list, list) else [resp_list])]
    if partial_matches: return random.choice(list(set(partial_matches)))
    # 4. Benzerlik Skoru (Kelime KesiÅŸimi) - Basit versiyon
    query_words = set(re.findall(r'\b\w{3,}\b', query_lower))
    best_score, best_responses = 0, []
    for key, resp_list in knowledge_base_dict.items():
        key_words = set(re.findall(r'\b\w{3,}\b', key.lower()))
        if not key_words: continue
        score = len(query_words.intersection(key_words)) / len(key_words) if key_words else 0
        if score > 0.6: # Benzerlik eÅŸiÄŸi
            options = resp_list if isinstance(resp_list, list) else [resp_list]
            if score > best_score: best_score, best_responses = score, options
            elif score == best_score: best_responses.extend(options)
    if best_responses: return random.choice(list(set(best_responses)))
    return None

# --- API AnahtarÄ± ve Gemini YapÄ±landÄ±rmasÄ± ---
gemini_model = None
gemini_init_error_global = None

def initialize_gemini_model():
    """Google Generative AI modelini session state'deki ayarlarla baÅŸlatÄ±r."""
    global gemini_init_error_global
    api_key = st.secrets.get("GOOGLE_API_KEY")
    if not api_key:
        gemini_init_error_global = "ğŸ›‘ Google API AnahtarÄ± Secrets'ta bulunamadÄ±! (st.secrets['GOOGLE_API_KEY'])"
        return None
    try:
        genai.configure(api_key=api_key)
        safety = [
            {"category": c, "threshold": "BLOCK_MEDIUM_AND_ABOVE"}
            for c in ["HARM_CATEGORY_HARASSMENT", "HARM_CATEGORY_HATE_SPEECH",
                      "HARM_CATEGORY_SEXUALLY_EXPLICIT", "HARM_CATEGORY_DANGEROUS_CONTENT"]
        ]
        model_name = st.session_state.get('gemini_model_name', 'gemini-1.5-flash-latest')
        config = genai.types.GenerationConfig(
            temperature=st.session_state.get('gemini_temperature', 0.7),
            top_p=st.session_state.get('gemini_top_p', 0.95),
            top_k=st.session_state.get('gemini_top_k', 40),
            max_output_tokens=st.session_state.get('gemini_max_tokens', 4096)
        )
        model = genai.GenerativeModel(model_name=model_name, safety_settings=safety, generation_config=config)
        gemini_init_error_global = None
        st.toast(f"âœ¨ Gemini modeli ({model_name}) yÃ¼klendi!", icon="ğŸ¤–")
        return model
    except Exception as e:
        gemini_init_error_global = f"ğŸ›‘ Gemini yapÄ±landÄ±rma hatasÄ±: {e}."
        print(f"ERROR: Gemini Init Failed: {e}")
        return None

# --- Supabase Ä°stemcisini BaÅŸlatma ---
supabase = None
supabase_error_global = None

@st.cache_resource(ttl=3600)
def init_supabase_client_cached():
    """Supabase istemcisini baÅŸlatÄ±r ve cache'ler."""
    global supabase_error_global
    if not create_client:
        supabase_error_global = "Supabase kÃ¼tÃ¼phanesi yÃ¼klenemedi. Loglama/Feedback devre dÄ±ÅŸÄ±."
        return None
    url = st.secrets.get("SUPABASE_URL")
    key = st.secrets.get("SUPABASE_SERVICE_KEY")
    if not url or not key:
        supabase_error_global = "Supabase URL/Key Secrets'ta bulunamadÄ±! Loglama/Feedback devre dÄ±ÅŸÄ±."
        return None
    try:
        client: Client = create_client(url, key)
        supabase_error_global = None
        st.toast("ğŸ”— Supabase baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±.", icon="ğŸ§±")
        return client
    except Exception as e:
        error = f"Supabase baÄŸlantÄ± hatasÄ±: {e}."
        if "invalid url" in str(e).lower(): error += " URL formatÄ±nÄ± kontrol edin."
        elif "invalid key" in str(e).lower(): error += " Service Key'i kontrol edin."
        supabase_error_global = error
        print(f"ERROR: Supabase Connection Failed: {e}")
        return None

# --- YARDIMCI FONKSÄ°YONLAR ---
def _get_session_id():
    """Oturum ID'sini alÄ±r veya oluÅŸturur."""
    if 'session_id' not in st.session_state: st.session_state.session_id = str(uuid.uuid4())
    return st.session_state.session_id

tts_engine = None
tts_init_error_global = None

@st.cache_resource
def init_tts_engine_cached():
    """Metin okuma (TTS) motorunu baÅŸlatÄ±r."""
    global tts_init_error_global
    try:
        engine = pyttsx3.init()
        tts_init_error_global = None
        st.toast("ğŸ”Š TTS motoru hazÄ±r.", icon="ğŸ—£ï¸")
        return engine
    except Exception as e:
        tts_init_error_global = f"âš ï¸ TTS motoru baÅŸlatÄ±lamadÄ±: {e}."
        print(f"ERROR: TTS Init Failed: {e}")
        return None

def speak(text):
    """Verilen metni sesli okur."""
    engine = globals().get('tts_engine')
    if not engine: st.toast("TTS motoru aktif deÄŸil.", icon="ğŸ”‡"); return
    if not st.session_state.get('tts_enabled', True): st.toast("TTS ayarlardan kapalÄ±.", icon="ğŸ”‡"); return
    try:
        cleaned = re.sub(r'[^\w\s.,!?-]', '', text) # Basit temizleme
        if not cleaned.strip(): st.toast("Okunacak metin yok.", icon="â„¹ï¸"); return
        engine.say(cleaned)
        engine.runAndWait()
    except RuntimeError as e: st.warning(f"TTS Ã§alÄ±ÅŸma zamanÄ± sorunu: {e}.", icon="ğŸ”Š")
    except Exception as e: st.error(f"TTS hatasÄ±: {e}", icon="ğŸ”¥"); print(f"ERROR: TTS Speak Failed: {e}")

def _clean_text(text):
    """Metindeki fazla boÅŸluklarÄ±/satÄ±rlarÄ± temizler."""
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'\n\s*\n', '\n\n', text)
    return text.strip()

@st.cache_data(ttl=600) # KazÄ±ma sonuÃ§larÄ±nÄ± 10dk cache'le
def scrape_url_content(url, timeout=REQUEST_TIMEOUT, max_chars=SCRAPE_MAX_CHARS):
    """URL'den ana metin iÃ§eriÄŸini kazÄ±r (cache'li)."""
    st.toast(f"ğŸŒ '{urlparse(url).netloc}' alÄ±nÄ±yor...", icon="â³")
    try:
        parsed = urlparse(url)
        if not all([parsed.scheme, parsed.netloc]) or parsed.scheme not in ['http', 'https']:
            st.warning(f"GeÃ§ersiz URL: {url}", icon="ğŸ”—"); return None
        headers = {'User-Agent': USER_AGENT, 'Accept-Language': 'tr-TR,tr;q=0.9', 'Accept': 'text/html', 'DNT': '1'}
        resp = requests.get(url, headers=headers, timeout=timeout, allow_redirects=True, stream=True)
        resp.raise_for_status()
        ctype = resp.headers.get('content-type', '').lower()
        if 'html' not in ctype:
            st.info(f"HTML deÄŸil ('{ctype}'). AtlanÄ±yor: {url}", icon="ğŸ“„"); resp.close(); return None

        html = ""; size = 0; max_size = max_chars * 12 # Max HTML boyutu
        try:
            for chunk in resp.iter_content(chunk_size=8192, decode_unicode=True, errors='ignore'):
                if chunk: html += chunk; size += len(chunk.encode('utf-8', 'ignore'))
                if size > max_size: st.warning(f"HTML Ã§ok bÃ¼yÃ¼k (> {max_size//1024}KB), kesiliyor.", icon="âœ‚ï¸"); break
        finally: resp.close()
        if not html: st.warning("BoÅŸ iÃ§erik alÄ±ndÄ±.", icon="ğŸ“„"); return None

        soup = BeautifulSoup(html, 'lxml')
        tags_remove = ["script", "style", "nav", "footer", "aside", "form", "button", "iframe", "header", "noscript", "link", "meta", "img", "svg", "video", "audio", "figure", "input", "select"]
        for tag in soup.find_all(tags_remove): tag.decompose()

        content = []
        selectors = ['article[class*="content"]', 'article[class*="post"]', 'main[id*="content"]', 'main', 'div[class*="post-body"]', 'div[class*="article-body"]', 'div[itemprop="articleBody"]', 'article', '.content', '#content']
        container = None
        for sel in selectors:
            found = soup.select(sel, limit=1)
            if found: container = found[0]; break

        min_len = 80; min_indicator = 1
        if container:
            paragraphs = container.find_all('p', limit=60)
            for p in paragraphs:
                text = _clean_text(p.get_text(separator=' ', strip=True))
                if len(text) > min_len and (text.count('.') + text.count('!') + text.count('?')) >= min_indicator: content.append(text)
        if not content or len(" ".join(content)) < 300: # Body fallback
             body = soup.body
             if body:
                 body_text = _clean_text(body.get_text(separator='\n', strip=True))
                 parts = [p.strip() for p in body_text.split('\n') if len(p.strip()) > min_len]
                 if len(" ".join(parts)) > 200:
                      st.toast("Ã–zel alan bulunamadÄ±, genel metin kullanÄ±ldÄ±.", icon="â„¹ï¸"); content = parts[:40]
                 else: st.toast("Sayfada anlamlÄ± iÃ§erik bulunamadÄ±.", icon="ğŸ“„"); return None
             else: st.toast("Body etiketi bulunamadÄ±.", icon="ğŸ“„"); return None

        full_text = "\n\n".join(content); cleaned = _clean_text(full_text)
        if not cleaned: st.toast("KazÄ±ma sonrasÄ± boÅŸ iÃ§erik.", icon="ğŸ“„"); return None
        final = cleaned[:max_chars] + ("..." if len(cleaned) > max_chars else "")
        st.toast(f"'{urlparse(url).netloc}' iÃ§eriÄŸi alÄ±ndÄ±.", icon="âœ…")
        return final
    except requests.exceptions.RequestException as e: st.toast(f"âš ï¸ AÄŸ hatasÄ± ({type(e).__name__}): {url}", icon='ğŸŒ')
    except Exception as e: st.toast(f"âš ï¸ KazÄ±ma hatasÄ±: {e}", icon='ğŸ”¥'); print(f"ERROR: Scraping '{url}' failed: {e}")
    return None

@st.cache_data(ttl=600) # Arama sonuÃ§larÄ±nÄ± 10dk cache'le
def search_web(query):
    """Web'de arama yapar (Wikipedia, DDG) ve sonuÃ§larÄ± dÃ¶ndÃ¼rÃ¼r."""
    st.toast(f"ğŸ” '{query}' aranÄ±yor...", icon="â³")
    wikipedia.set_lang("tr"); result = None
    # 1. Wikipedia
    try:
        wp_page = wikipedia.page(query, auto_suggest=False, redirect=True)
        summary = wikipedia.summary(query, sentences=6, auto_suggest=False, redirect=True)
        result = f"**Wikipedia ({wp_page.title}):**\n\n{_clean_text(summary)}\n\nKaynak: {wp_page.url}"
        st.toast(f"âœ… Wikipedia'dan '{wp_page.title}' bulundu.", icon="ğŸ“š"); return result
    except wikipedia.exceptions.PageError: st.toast(f"â„¹ï¸ Wikipedia'da '{query}' bulunamadÄ±.", icon="ğŸ¤·")
    except wikipedia.exceptions.DisambiguationError as e: result = f"**Wikipedia'da Ã‡ok AnlamlÄ± ({query}):**\n{e.options[:3]}..." # Devam et
    except Exception as e: st.toast(f"âš ï¸ Wikipedia hatasÄ±: {e}", icon="ğŸ”¥")
    # 2. DuckDuckGo
    ddg_url = None
    try:
        with DDGS(headers={'User-Agent': USER_AGENT}, timeout=REQUEST_TIMEOUT) as ddgs:
            ddg_results = list(ddgs.text(query, region='tr-tr', safesearch='moderate', max_results=3))
            if ddg_results:
                best_res = ddg_results[0]
                snippet = best_res.get('body'); url = best_res.get('href')
                if snippet and url:
                    ddg_url = unquote(url); domain = urlparse(ddg_url).netloc
                    st.toast(f"â„¹ï¸ DDG'den '{domain}' Ã¶zeti bulundu.", icon="ğŸ¦†")
                    result = f"**Web Ã–zeti (DDG - {domain}):**\n\n{_clean_text(snippet)}\n\nKaynak: {ddg_url}"
    except Exception as e: st.toast(f"âš ï¸ DDG hatasÄ±: {e}", icon="ğŸ”¥")
    # 3. KazÄ±ma (DDG URL varsa)
    if ddg_url:
        scraped = scrape_url_content(ddg_url) # Cache'li fonksiyonu Ã§aÄŸÄ±r
        if scraped:
            domain = urlparse(ddg_url).netloc
            result = f"**Web SayfasÄ±ndan ({domain}):**\n\n{scraped}\n\nKaynak: {ddg_url}" # KazÄ±nan iÃ§erik Ã¶ncelikli
            st.toast(f"âœ… '{domain}' iÃ§eriÄŸi kazÄ±ndÄ±.", icon="ğŸ“„")
        elif result: st.toast("â„¹ï¸ Sayfa kazÄ±namadÄ±, DDG Ã¶zeti kullanÄ±lÄ±yor.", icon="ğŸ“")
        else: result = f"Detay iÃ§in: {ddg_url}" # Sadece URL kaldÄ±ysa
    if not result: st.toast(f"'{query}' iÃ§in web sonucu bulunamadÄ±.", icon="âŒ")
    return result

# --- Sohbet GeÃ§miÅŸi YÃ¶netimi ---
@st.cache_data(ttl=86400)
def load_all_chats_cached(file_path=CHAT_HISTORY_FILE):
    """TÃ¼m sohbet geÃ§miÅŸlerini dosyadan yÃ¼kler (cache'li)."""
    if os.path.exists(file_path):
        try:
            with open(file_path, "r", encoding="utf-8") as f: content = f.read()
            if content and content.strip():
                data = json.loads(content)
                if isinstance(data, dict): return {str(k): v for k, v in data.items()}
                else: # Eski format veya bozuk
                    st.warning(f"GeÃ§ersiz format ({file_path}). Yeni yapÄ±ya geÃ§iliyor.", icon="âš ï¸")
                    try: os.rename(file_path, f"{file_path}.backup_{int(time.time())}")
                    except OSError: pass; return {}
            else: return {} # BoÅŸ dosya
        except json.JSONDecodeError:
            st.error(f"Sohbet dosyasÄ± ({file_path}) bozuk. Yeni baÅŸlatÄ±lÄ±yor.", icon="ğŸ”¥")
            try: os.rename(file_path, f"{file_path}.corrupt_{int(time.time())}")
            except OSError: pass; return {}
        except Exception as e: st.error(f"Sohbet yÃ¼klenirken hata: {e}", icon="ğŸ”¥"); return {}
    return {}

def save_all_chats(chats_dict, file_path=CHAT_HISTORY_FILE):
    """TÃ¼m sohbetleri dosyaya kaydeder."""
    try:
        with open(file_path, "w", encoding="utf-8") as f: json.dump(chats_dict, f, ensure_ascii=False, indent=2)
    except Exception as e: st.error(f"Sohbet kaydedilemedi: {e}", icon="ğŸ”¥"); print(f"ERROR: Save chats failed: {e}")

# --- Gemini YanÄ±t Alma ---
def get_gemini_response_cached(prompt, history, stream=False):
    """Gemini API'den yanÄ±t alÄ±r."""
    model = globals().get('gemini_model')
    if not model: return f"{GEMINI_ERROR_PREFIX} Model aktif deÄŸil."
    validated_history = []
    for msg in history: # API formatÄ±nÄ± doÄŸrula/dÃ¼zelt
        role, parts = msg.get('role'), msg.get('parts')
        if role in ['user', 'model'] and isinstance(parts, str) and parts.strip():
             validated_history.append({'role': role, 'parts': [parts]}) # API 'parts'Ä± liste bekler
        elif role in ['user', 'model'] and isinstance(parts, list) and parts and isinstance(parts[0], str):
             validated_history.append(msg) # Zaten doÄŸru formatta
    try:
        chat = model.start_chat(history=validated_history)
        response = chat.send_message(prompt, stream=stream)
        if stream: return response
        else: # Stream deÄŸilse iÃ§eriÄŸi kontrol et
             if response.parts: return "".join(p.text for p in response.parts if hasattr(p, 'text'))
             else: # Neden boÅŸ geldi?
                 reason = getattr(response.prompt_feedback, 'block_reason', None)
                 if reason: msg = f"YanÄ±t engellendi ({reason})."
                 else: reason = getattr(response.candidates[0], 'finish_reason', None) if response.candidates else None; msg = f"YanÄ±t tam deÄŸil ({reason})." if reason != 'STOP' else "BoÅŸ yanÄ±t."
                 st.warning(msg, icon="ğŸ›¡ï¸" if "block" in msg.lower() else "âš ï¸"); return f"{GEMINI_ERROR_PREFIX} {msg}"
    except (genai.types.BlockedPromptException, genai.types.StopCandidateException) as e: st.error(f"Gemini HatasÄ±: {e}", icon="ğŸ›‘"); return f"{GEMINI_ERROR_PREFIX} API KÄ±sÄ±tlamasÄ±: {e}"
    except requests.exceptions.RequestException as e: st.error(f"Gemini AÄŸ HatasÄ±: {e}", icon="ğŸ“¡"); return f"{GEMINI_ERROR_PREFIX} AÄŸ HatasÄ±: {e}"
    except Exception as e: st.error(f"Gemini API HatasÄ±: {e}", icon="ğŸ”¥"); print(f"ERROR: Gemini API failed: {e}"); return f"{GEMINI_ERROR_PREFIX} API HatasÄ±: {e}"

# --- Supabase Loglama ---
def log_to_supabase(table, data):
    """Veriyi Supabase'e loglar."""
    client = globals().get('supabase')
    if not client: print(f"INFO: Supabase unavailable, skip log to '{table}'."); return False
    try:
        defaults = {'user_name': st.session_state.get('user_name', 'N/A'), 'session_id': _get_session_id(), 'app_version': APP_VERSION, 'chat_id': st.session_state.get('active_chat_id', 'N/A')}
        log_data = {**defaults, **data} # VarsayÄ±lanlarÄ± ekle
        client.table(table).insert(log_data).execute()
        # print(f"DEBUG: Supabase log success to '{table}'.") # BaÅŸarÄ± logu
        return True
    except SupabaseAPIError as e: st.toast(f"âš ï¸ Loglama hatasÄ±: {e.message}", icon="ğŸ’¾"); print(f"ERROR: Supabase API Error ({table}): {e}"); return False
    except Exception as e: st.error("Loglama sÄ±rasÄ±nda kritik hata!"); print(f"ERROR: Supabase Log Critical ({table}): {e}"); return False

def log_interaction(prompt, response, source, msg_id, chat_id):
    """EtkileÅŸimi loglar."""
    return log_to_supabase(SUPABASE_TABLE_LOGS, {"user_prompt": prompt, "ai_response": response, "response_source": source, "message_id": msg_id, "chat_id": chat_id})

def log_feedback(msg_id, prompt, response, f_type, comment=""):
    """Geri bildirimi loglar."""
    data = {"message_id": msg_id, "user_prompt": prompt, "ai_response": response, "feedback_type": f_type, "comment": comment}
    if log_to_supabase(SUPABASE_TABLE_FEEDBACK, data): st.toast("Geri bildiriminiz iÃ§in teÅŸekkÃ¼rler!", icon="ğŸ’Œ"); return True
    else: st.toast("Geri bildirim gÃ¶nderilemedi.", icon="ğŸ˜”"); return False

# --- YanÄ±t Orkestrasyonu ---
def get_hanogt_response_orchestrator(prompt, history, msg_id, chat_id, use_stream=False):
    """FarklÄ± kaynaklardan yanÄ±t alÄ±r."""
    response, source_tag = None, "Bilinmiyor"
    # 1. KB / Fonksiyon
    kb_resp = kb_chatbot_response(prompt, KNOWLEDGE_BASE)
    if kb_resp:
        source_tag = "Fonksiyonel" if prompt.lower() in DYNAMIC_FUNCTIONS_MAP else "Bilgi TabanÄ±"
        log_interaction(prompt, kb_resp, source_tag, msg_id, chat_id)
        return kb_resp, f"{APP_NAME} ({source_tag})"
    # 2. Gemini
    if globals().get('gemini_model'):
        gemini_resp = get_gemini_response_cached(prompt, history, stream=use_stream)
        if gemini_resp:
            if use_stream: return gemini_resp, f"{APP_NAME} (Gemini Stream)" # Loglama stream sonrasÄ± yapÄ±lÄ±r
            elif isinstance(gemini_resp, str) and not gemini_resp.startswith(GEMINI_ERROR_PREFIX):
                 source_tag = "Gemini"; log_interaction(prompt, gemini_resp, source_tag, msg_id, chat_id); return gemini_resp, f"{APP_NAME} ({source_tag})"
            # else: Gemini hatasÄ± veya boÅŸ yanÄ±t, devam et
    # 3. Web Arama (Gerekliyse)
    is_q = "?" in prompt or any(k in prompt.lower() for k in ["nedir", "kimdir", "nasÄ±l", "bilgi", "araÅŸtÄ±r", "haber"])
    if not response and is_q and len(prompt.split()) > 2:
        web_resp = search_web(prompt) # Cache'li fonksiyon
        if web_resp:
            if "Wikipedia" in web_resp: source_tag = "Wikipedia"
            elif "Web SayfasÄ±ndan" in web_resp: source_tag = "Web KazÄ±ma"
            elif "Web Ã–zeti" in web_resp: source_tag = "Web Ã–zeti (DDG)"
            else: source_tag = "Web Arama"
            log_interaction(prompt, web_resp, source_tag, msg_id, chat_id); return web_resp, f"{APP_NAME} ({source_tag})"
    # 4. VarsayÄ±lan YanÄ±t
    defaults = [f"ÃœzgÃ¼nÃ¼m {st.session_state.get('user_name', '')}, yardÄ±mcÄ± olamÄ±yorum.", "AnlayamadÄ±m, farklÄ± sorar mÄ±sÄ±nÄ±z?", "Bu konuda bilgim yok.", "Ã–ÄŸreniyorum..."]
    response = random.choice(defaults); source_tag = "VarsayÄ±lan"
    log_interaction(prompt, response, source_tag, msg_id, chat_id)
    return response, f"{APP_NAME} ({source_tag})"

# --- YaratÄ±cÄ± ModÃ¼ller ---
def creative_response_generator(prompt, length="orta", style="genel"):
    """Yerel basit yaratÄ±cÄ± metin Ã¼retir."""
    templates = {"genel": ["Ä°ÅŸte bir fikir: {}", "Hayal edelim: {}"], "ÅŸiirsel": ["Kalbimden: {}", "SÃ¶zcÃ¼klerle: {}"], "hikaye": ["Bir varmÄ±ÅŸ: {}", "Sahne sizin: {}"]}
    template = random.choice(templates.get(style, templates["genel"]))
    idea = generate_new_idea_creative(prompt, style)
    sentences = [s.strip() for s in idea.split('.') if s.strip()]
    n = len(sentences)
    if length == "kÄ±sa" and n > 1: idea = ". ".join(sentences[:max(1, n // 3)]) + "."
    elif length == "uzun" and n > 0: idea += f"\n\nDahasÄ±, {generate_new_idea_creative(prompt[::-1], style)}"
    return template.format(idea)

def generate_new_idea_creative(seed, style="genel"):
    """Rastgele kelimelerle fikir Ã¼retir."""
    elems = ["zaman kristalleri", "psiÅŸik ormanlar", "rÃ¼ya mimarisi", "kuantum kÃ¶pÃ¼ÄŸÃ¼", "gÃ¶lge enerjisi"]
    acts = ["dokur", "Ã§Ã¶zer", "yansÄ±tÄ±r", "inÅŸa eder", "fÄ±sÄ±ldar"]
    outs = ["kaderi", "varoluÅŸun kodunu", "bilincin sÄ±nÄ±rlarÄ±nÄ±", "kadim sÄ±rlarÄ±", "evrenin melodisini"]
    words = re.findall(r'\b\w{4,}\b', seed.lower())
    seeds = random.sample(words, k=min(len(words), 1)) + ["gizem"]
    e1, a1, o1 = random.choice(elems), random.choice(acts), random.choice(outs)
    return f"{seeds[0].capitalize()} {a1}, {e1} aracÄ±lÄ±ÄŸÄ±yla {o1}."

def advanced_word_generator(base):
    """Yeni 'teknik' kelimeler tÃ¼retir."""
    if not base or len(base) < 2: return "KelimatÃ¶r"
    v="aeÄ±ioÃ¶uÃ¼"; c="bcÃ§dfgÄŸhjklmnprsÅŸtvyz"; cln = "".join(filter(str.isalpha, base.lower()))
    if not cln: return "SÃ¶zcÃ¼kMimar"
    pre = ["bio", "krono", "psiko", "neo", "mega", "nano", "astro", "poli", "meta", "trans", "ultra", "xeno"]
    suf = ["genez", "sfer", "nomi", "tek", "loji", "tronik", "morf", "vers", "dinamik", "matik", "kinezis", "skop"]
    core = cln[random.randint(0, max(0, len(cln)-3)):][:random.randint(2,3)] if len(cln)>2 and random.random()<0.6 else "".join(random.choice(c if i%2 else v) for i in range(random.randint(3,4)))
    word = core
    if random.random()>0.4: word = random.choice(pre) + word
    if random.random()>0.4: word += random.choice(suf)
    return word.capitalize() if len(word)>1 else word

# --- GÃ¶rsel OluÅŸturucu ---
def generate_prompt_influenced_image(prompt):
    """Prompt'a gÃ¶re basit kural tabanlÄ± gÃ¶rsel oluÅŸturur."""
    w, h = 512, 512; p_lower = prompt.lower()
    themes = { # Daha fazla tema eklenebilir
        "gÃ¼neÅŸ": {"bg": [(255,230,150),(255,160,0)], "sh": [{"t":"circle","c":(255,255,0,220),"p":(0.25,0.25),"s":0.2}]},
        "ay": {"bg": [(10,10,50),(40,40,100)], "sh": [{"t":"circle","c":(240,240,240,200),"p":(0.75,0.2),"s":0.15}]},
        "gÃ¶kyÃ¼zÃ¼": {"bg": [(135,206,250),(70,130,180)], "sh": []},
        "bulut": {"bg":None, "sh": [{"t":"ellipse","c":(255,255,255,180),"p":(random.uniform(0.2,0.8),random.uniform(0.1,0.4)),"swh":(random.uniform(0.15,0.35),random.uniform(0.08,0.15))} for _ in range(random.randint(2,4))]},
        "deniz": {"bg": [(0,105,148),(0,0,100)], "sh": [{"t":"rect","c":(60,120,180,150),"p":(0.5,0.75),"swh":(1.0,0.5)}]},
        "orman": {"bg": [(34,139,34),(0,100,0)], "sh": [{"t":"tri","c":(random.randint(0,30),random.randint(70,100),random.randint(0,30),200),"p":(random.uniform(0.1,0.9),random.uniform(0.55,0.85)),"s":random.uniform(0.08,0.25)} for _ in range(random.randint(7,12))]},
        # --- DÃœZELTÄ°LMÄ°Å "aÄŸaÃ§" TANIMI (SyntaxError Fix) ---
        "aÄŸaÃ§": {
            "bg": [(180, 220, 180), (140, 190, 140)],
            "sh": [ # 'sh' kÄ±saltmasÄ± kullanÄ±ldÄ± (shapes yerine)
                {"t": "rect", "c": (139, 69, 19, 255), "p": (random.uniform(0.2, 0.8), 0.75), "swh": (0.06, 0.4)}, # GÃ¶vde
                {"t": "ellipse", "c": (34, 139, 34, 200), "p": (random.uniform(0.2, 0.8), 0.45), "swh": (0.3, 0.25)}  # Tepe (Basit pos)
            ]
        },
        # --- DÃœZELTME BÄ°TTÄ° ---
        "daÄŸ": {"bg": [(200,200,200),(100,100,100)], "sh": [{"t":"poly","c":(random.randint(130,170),random.randint(130,170),random.randint(130,170),230),"pts":[(random.uniform(0.1,0.4),0.85),(0.5,random.uniform(0.1,0.4)),(random.uniform(0.6,0.9),0.85)]} for _ in range(random.randint(1,3))]},
        "ÅŸehir": {"bg": [(100,100,120),(50,50,70)], "sh": [{"t":"rect","c":(random.randint(60,100),random.randint(60,100),random.randint(70,110),random.randint(180,220)),"p":(random.uniform(0.1,0.9),random.uniform(0.4,0.85)),"swh":(random.uniform(0.04,0.15),random.uniform(0.15,0.65))} for _ in range(random.randint(8,15))]},
        "kar": {"bg":None, "sh": [{"t":"circle","c":(255,255,255,150),"p":(random.random(),random.random()),"s":0.005} for _ in range(100)]},
        "yÄ±ldÄ±z": {"bg":None, "sh": [{"t":"circle","c":(255,255,200,200),"p":(random.random(),random.uniform(0,0.5)),"s":0.003} for _ in range(70)]},
    }
    bg1, bg2 = (random.randint(30,120),)*3, (random.randint(120,220),)*3
    shapes = []; themes_applied = 0
    for kw, theme in themes.items():
        if kw in p_lower:
            if theme["bg"] and themes_applied==0: bg1, bg2 = theme["bg"]
            shapes.extend(theme["sh"]); themes_applied+=1

    img = Image.new('RGBA', (w,h), (0,0,0,0)); draw = ImageDraw.Draw(img)
    for y in range(h): # Arka plan gradient
        r = y/h; R,G,B = [int(bg1[i]*(1-r)+bg2[i]*r) for i in range(3)]; draw.line([(0,y),(w,y)],fill=(R,G,B,255))
    # Åekiller (kÄ±saltÄ±lmÄ±ÅŸ isimler kullanÄ±ldÄ±: t, c, p, s, swh, pts)
    for s in shapes:
        try:
            st, sc, sp = s["t"], s["c"], s.get("p"); out = (0,0,0,50) if len(sc)==4 and sc[3]<250 else None
            if sp: cx, cy = int(sp[0]*w), int(sp[1]*h)
            if st=="circle": r=int(s["s"]*min(w,h)/2); draw.ellipse((cx-r,cy-r,cx+r,cy+r),fill=sc,outline=out)
            elif st=="rect" or st=="ellipse": wr,hr=s["swh"]; wp,hp=int(wr*w),int(hr*h); draw.rectangle((cx-wp//2,cy-hp//2,cx+wp//2,cy+hp//2),fill=sc,outline=out) if st=="rect" else draw.ellipse((cx-wp//2,cy-hp//2,cx+wp//2,cy+hp//2),fill=sc,outline=out)
            elif st=="tri": sz=int(s["s"]*min(w,h)); p1,p2,p3=(cx,cy-int(sz*0.58)),(cx-sz//2,cy+int(sz*0.3)),(cx+sz//2,cy+int(sz*0.3)); draw.polygon([p1,p2,p3],fill=sc,outline=out)
            elif st=="poly": pts_px=[(int(p[0]*w),int(p[1]*h)) for p in s["pts"]]; draw.polygon(pts_px,fill=sc,outline=out)
        except Exception as e: print(f"DEBUG: Shape draw error {s}: {e}"); continue
    if themes_applied==0: # Rastgele ÅŸekiller
        for _ in range(random.randint(4,7)): x,y=random.randint(0,w),random.randint(0,h); clr=tuple(random.randint(50,250) for _ in range(3))+(random.randint(150,220),); r=random.randint(20,70); draw.ellipse((x-r,y-r,x+r,y+r),fill=clr) if random.random()>0.5 else draw.rectangle((x-r//2,y-r//2,x+r//2,y+r//2),fill=clr)
    # Metin yazdÄ±rma (hata kontrolÃ¼ iÃ§inde)
    try:
        font=ImageFont.load_default(); txt=prompt[:80]
        if os.path.exists(FONT_FILE):
             try: fsize=max(14,min(28,int(w/(len(txt)*0.3+10)))); font=ImageFont.truetype(FONT_FILE,fsize)
             except IOError: st.toast(f"Font ({FONT_FILE}) yÃ¼klenemedi.",icon="âš ï¸")
        bb=draw.textbbox((0,0),txt,font=font,anchor="lt") if hasattr(draw,'textbbox') else draw.textsize(txt,font=font); tw,th=bb[2]-bb[0] if hasattr(draw,'textbbox') else bb[0], bb[3]-bb[1] if hasattr(draw,'textbbox') else bb[1]
        tx,ty=(w-tw)/2, h*0.95-th; draw.text((tx+1,ty+1),txt,font=font,fill=(0,0,0,150)); draw.text((tx,ty),txt,font=font,fill=(255,255,255,230))
    except Exception as e: st.toast(f"Metin yazÄ±lamadÄ±: {e}",icon="ğŸ“")
    return img.convert("RGB")

# --- Session State BaÅŸlatma ---
def initialize_session_state():
    """Session State iÃ§in varsayÄ±lan deÄŸerleri ayarlar."""
    defaults = {
        'all_chats': {}, 'active_chat_id': None, 'next_chat_id_counter': 0,
        'app_mode': "YazÄ±lÄ± Sohbet", 'user_name': None, 'user_avatar_bytes': None,
        'show_main_app': False, 'greeting_message_shown': False,
        'tts_enabled': True, 'gemini_stream_enabled': True,
        'gemini_temperature': 0.7, 'gemini_top_p': 0.95, 'gemini_top_k': 40,
        'gemini_max_tokens': 4096, 'gemini_model_name': 'gemini-1.5-flash-latest',
        'message_id_counter': 0, 'last_ai_response_for_feedback': None,
        'last_user_prompt_for_feedback': None, 'current_message_id_for_feedback': None,
        'feedback_comment_input': "", 'show_feedback_comment_form': False,
        'session_id': str(uuid.uuid4()), 'last_feedback_type': 'positive',
        'models_initialized': False
    }
    for k, v in defaults.items():
        if k not in st.session_state: st.session_state[k] = v

initialize_session_state()

# --- Modelleri ve Ä°stemcileri BaÅŸlatma (Sadece Ä°lk Ã‡alÄ±ÅŸtÄ±rmada) ---
if not st.session_state.models_initialized:
    print("INFO: Initializing models, clients, and loading data...")
    gemini_model = initialize_gemini_model()
    supabase = init_supabase_client_cached()
    tts_engine = init_tts_engine_cached()
    st.session_state.all_chats = load_all_chats_cached()
    if not st.session_state.active_chat_id and st.session_state.all_chats:
        st.session_state.active_chat_id = list(st.session_state.all_chats.keys())[-1] # En son sohbeti aktif yap
    user_greeting = st.session_state.get('user_name', "kullanÄ±cÄ±")
    KNOWLEDGE_BASE = load_knowledge_from_file(user_name_for_greeting=user_greeting)
    st.session_state.models_initialized = True
    print("INFO: Initialization complete.")
else: # Sonraki Ã§alÄ±ÅŸtÄ±rmalarda global deÄŸiÅŸkenlerden al
    gemini_model = globals().get('gemini_model')
    supabase = globals().get('supabase')
    tts_engine = globals().get('tts_engine')
    user_greeting = st.session_state.get('user_name', "kullanÄ±cÄ±")
    KNOWLEDGE_BASE = load_knowledge_from_file(user_name_for_greeting=user_greeting) # KB'yi gÃ¼ncel tut

# Global hata mesajlarÄ±nÄ± al
gemini_init_error = globals().get('gemini_init_error_global')
supabase_error = globals().get('supabase_error_global')
tts_init_error = globals().get('tts_init_error_global')

# GiriÅŸ yapÄ±ldÄ±ysa ana uygulamayÄ± gÃ¶ster
if st.session_state.user_name and not st.session_state.show_main_app:
    st.session_state.show_main_app = True

# --- ARAYÃœZ BÃ–LÃœMLERÄ° --- (Fonksiyon TanÄ±mlarÄ±)
# display_settings_section, display_chat_list_and_about,
# display_chat_message_with_feedback, display_feedback_form_if_active,
# display_chat_interface_main fonksiyonlarÄ± Ã¶nceki yanÄ±ttaki gibi
# (iÃ§erikleri buraya tekrar eklenmedi, sadece fonksiyon isimleri referans olarak bÄ±rakÄ±ldÄ±)
# Ã–NEMLÄ°: Bu fonksiyonlarÄ±n iÃ§eriÄŸini bir Ã¶nceki yanÄ±ttan alÄ±p buraya eklemeniz gerekir.
# Sadece `display_settings_section` iÃ§indeki Gemini ayarlarÄ± bÃ¶lÃ¼mÃ¼nÃ¼n
# nested expander olmadan yapÄ±ldÄ±ÄŸÄ± versiyonu kullanÄ±n.

# Ã–nceki YanÄ±ttan Kopyalanacak FonksiyonlarÄ±n TanÄ±mlarÄ±:
def display_settings_section():
    """Ayarlar ve KiÅŸiselleÅŸtirme bÃ¶lÃ¼mÃ¼nÃ¼ ana alanda (expander iÃ§inde) gÃ¶sterir."""
    with st.expander("âš™ï¸ Ayarlar & KiÅŸiselleÅŸtirme", expanded=False):
        col1, col2 = st.columns([0.8, 0.2]) # Profil ve Avatar iÃ§in kolonlar
        with col1:
            st.markdown(f"**HoÅŸ Geldin, {st.session_state.user_name}!**")
            new_user_name = st.text_input("AdÄ±nÄ±zÄ± DeÄŸiÅŸtirin:", value=st.session_state.user_name, key="change_name_main_input", label_visibility="collapsed")
            if new_user_name != st.session_state.user_name and new_user_name.strip():
                st.session_state.user_name = new_user_name.strip()
                load_knowledge_from_file.clear() # KB cache'ini temizle
                st.toast("AdÄ±nÄ±z gÃ¼ncellendi!", icon="âœï¸"); st.rerun()
        with col2:
            if st.session_state.user_avatar_bytes:
                st.image(st.session_state.user_avatar_bytes, width=60, use_column_width='auto')
                if st.button("ğŸ—‘ï¸", key="remove_avatar_main_button", help="AvatarÄ± kaldÄ±r", use_container_width=True):
                    st.session_state.user_avatar_bytes = None
                    st.toast("Avatar kaldÄ±rÄ±ldÄ±.", icon="ğŸ—‘ï¸"); st.rerun()
            else: st.caption("Avatar Yok") # Daha kompakt

        uploaded_avatar_file = st.file_uploader("Avatar YÃ¼kle (Max 2MB):", type=["png", "jpg", "jpeg"], key="avatar_uploader_main_file", label_visibility="collapsed")
        if uploaded_avatar_file:
            if uploaded_avatar_file.size > 2 * 1024 * 1024: st.error("Dosya > 2MB!", icon="ï¸")
            else: st.session_state.user_avatar_bytes = uploaded_avatar_file.getvalue(); st.toast("Avatar gÃ¼ncellendi!", icon="ğŸ–¼ï¸"); st.rerun()
        st.caption("Avatar sadece bu oturumda saklanÄ±r.")

        st.divider()
        st.subheader("ğŸ¤– Yapay Zeka ve ArayÃ¼z")
        tcol1, tcol2 = st.columns(2)
        with tcol1:
             engine_ready = globals().get('tts_engine') is not None
             st.session_state.tts_enabled = st.toggle("Metin Okuma (TTS)", value=st.session_state.tts_enabled, disabled=not engine_ready, help="AI yanÄ±tlarÄ±nÄ± sesli oku.")
        with tcol2:
             st.session_state.gemini_stream_enabled = st.toggle("YanÄ±t AkÄ±ÅŸÄ± (Stream)", value=st.session_state.gemini_stream_enabled, help="YanÄ±tlarÄ± kelime kelime al.")

        # --- Hanogt AI (Gemini) GeliÅŸmiÅŸ YapÄ±landÄ±rma ---
        st.markdown("---")
        st.markdown("##### ğŸ§  Hanogt AI GeliÅŸmiÅŸ YapÄ±landÄ±rma")
        gcol1, gcol2 = st.columns(2)
        with gcol1:
            st.session_state.gemini_model_name = st.selectbox("AI Modeli:", ['gemini-1.5-flash-latest', 'gemini-1.5-pro-latest'], index=0 if st.session_state.gemini_model_name == 'gemini-1.5-flash-latest' else 1, key="gemini_model_selector_main", help="Model yetenekleri/maliyetleri farklÄ±dÄ±r.")
            st.session_state.gemini_temperature = st.slider("SÄ±caklÄ±k:", 0.0, 1.0, st.session_state.gemini_temperature, 0.05, key="gemini_temp_slider_main", help="YaratÄ±cÄ±lÄ±k (0=Kesin, 1=YaratÄ±cÄ±)")
            st.session_state.gemini_max_tokens = st.slider("Maks Token:", 256, 8192, st.session_state.gemini_max_tokens, 128, key="gemini_max_tokens_slider_main", help="Max yanÄ±t uzunluÄŸu")
        with gcol2:
            st.session_state.gemini_top_k = st.slider("Top K:", 1, 100, st.session_state.gemini_top_k, 1, key="gemini_top_k_slider_main", help="Kelime SeÃ§im Ã‡eÅŸitliliÄŸi")
            st.session_state.gemini_top_p = st.slider("Top P:", 0.0, 1.0, st.session_state.gemini_top_p, 0.05, key="gemini_top_p_slider_main", help="Kelime SeÃ§im OdaklÄ±lÄ±ÄŸÄ±")
            if st.button("âš™ï¸ AI AyarlarÄ±nÄ± Uygula", key="reload_gemini_settings_main_btn", use_container_width=True, type="primary", help="SeÃ§ili AI modelini ve parametreleri yeniden yÃ¼kler."):
                global gemini_model
                with st.spinner("AI modeli yeniden baÅŸlatÄ±lÄ±yor..."): gemini_model = initialize_gemini_model()
                if not gemini_model: st.error("AI modeli yÃ¼klenemedi.")
                st.rerun()

        # --- GeÃ§miÅŸ YÃ¶netimi ---
        st.divider()
        st.subheader("ğŸ§¼ GeÃ§miÅŸ YÃ¶netimi")
        if st.button("ğŸ§¹ TÃœM Sohbet GeÃ§miÅŸini Sil", use_container_width=True, type="secondary", key="clear_all_history_main_btn", help="Dikkat! KaydedilmiÅŸ tÃ¼m sohbetleri siler."):
            if st.session_state.all_chats:
                st.session_state.all_chats = {}; st.session_state.active_chat_id = None
                save_all_chats({}) # DosyayÄ± da boÅŸalt
                st.toast("TÃœM sohbet geÃ§miÅŸi silindi!", icon="ğŸ—‘ï¸"); st.rerun()
            else: st.toast("Sohbet geÃ§miÅŸi zaten boÅŸ.", icon="â„¹ï¸")

def display_chat_list_and_about(left_column):
    """Sol kolonda sohbet listesini ve HakkÄ±nda bÃ¶lÃ¼mÃ¼nÃ¼ gÃ¶sterir."""
    with left_column:
        st.markdown("#### Sohbetler")
        if st.button("â• Yeni Sohbet", use_container_width=True, key="new_chat_button"):
            st.session_state.next_chat_id_counter += 1; ts = int(time.time())
            new_id = f"chat_{st.session_state.next_chat_id_counter}_{ts}"
            st.session_state.all_chats[new_id] = []
            st.session_state.active_chat_id = new_id
            save_all_chats(st.session_state.all_chats); st.rerun()

        st.markdown("---")
        chat_list_container = st.container(height=400, border=False)
        with chat_list_container:
            chats = st.session_state.all_chats
            sorted_ids = sorted(chats.keys(), key=lambda x: int(x.split('_')[-1]), reverse=True)
            if not sorted_ids: st.caption("HenÃ¼z bir sohbet yok.")
            else:
                active_id = st.session_state.get('active_chat_id')
                for chat_id in sorted_ids:
                    history = chats.get(chat_id, [])
                    first_msg = next((m.get('parts','') for m in history if m.get('role')=='user'), None)
                    title = f"Sohbet {chat_id.split('_')[1]}"
                    if first_msg: title = first_msg[:35] + ("..." if len(first_msg)>35 else "")
                    elif history: title = "BaÅŸlÄ±ksÄ±z Sohbet"

                    lcol, rcol = st.columns([0.8, 0.2])
                    btn_type = "primary" if active_id == chat_id else "secondary"
                    if lcol.button(title, key=f"select_{chat_id}", use_container_width=True, type=btn_type, help=f"'{title}' aÃ§"):
                        if active_id != chat_id: st.session_state.active_chat_id = chat_id; st.rerun()
                    if rcol.button("âŒ", key=f"delete_{chat_id}", use_container_width=True, help=f"'{title}' sil", type="secondary"):
                         if chat_id in chats:
                             del chats[chat_id]
                             if active_id == chat_id:
                                 remaining = sorted(chats.keys(), key=lambda x: int(x.split('_')[-1]), reverse=True)
                                 st.session_state.active_chat_id = remaining[0] if remaining else None
                             save_all_chats(chats); st.toast(f"'{title}' silindi.", icon="ğŸ—‘ï¸"); st.rerun()

        st.markdown("<br>", unsafe_allow_html=True)
        with st.expander("â„¹ï¸ Uygulama HakkÄ±nda", expanded=False):
             st.markdown(f"**{APP_NAME} v{APP_VERSION}**\n\nYapay zeka destekli kiÅŸisel asistan.\n\nGeliÅŸtirici: **Hanogt**\n\nTeknolojiler: Streamlit, Gemini API, Python...\n\nÂ© 2024-{CURRENT_YEAR}")
             st.caption(f"Oturum: {_get_session_id()[:8]}...")

def display_chat_message_with_feedback(msg_data, msg_idx, chat_id):
    """Tek bir sohbet mesajÄ±nÄ± formatlar ve gÃ¶sterir."""
    role = msg_data.get('role', 'model')
    content = msg_data.get('parts', '')
    sender = msg_data.get('sender_display', APP_NAME if role == 'model' else st.session_state.user_name)
    is_user = (role == 'user')
    avatar = "ğŸ§‘"
    if is_user:
        if st.session_state.user_avatar_bytes:
            try: avatar = Image.open(BytesIO(st.session_state.user_avatar_bytes))
            except: pass
    else: # AI Avatar
        if "Gemini" in sender: avatar = "âœ¨"
        elif "Web" in sender or "Wikipedia" in sender: avatar = "ğŸŒ"
        elif "Bilgi TabanÄ±" in sender or "Fonksiyonel" in sender: avatar = "ğŸ“š"
        else: avatar = "ğŸ¤–"

    with st.chat_message(role, avatar=avatar):
        if "```" in content: # Kod bloÄŸu formatlama
            parts = content.split("```")
            for i, part in enumerate(parts):
                if i % 2 == 1:
                    lang_match = re.match(r"(\w+)\n", part)
                    lang = lang_match.group(1) if lang_match else None
                    code = part[len(lang)+1:] if lang and part.startswith(lang+"\n") else part
                    st.code(code, language=lang)
                    if st.button("ğŸ“‹", key=f"copy_{chat_id}_{msg_idx}_{i}", help="Kodu kopyala"):
                        st.write_to_clipboard(code); st.toast("Kod kopyalandÄ±!", icon="âœ…")
                elif part.strip(): st.markdown(part, unsafe_allow_html=True)
        elif content.strip(): st.markdown(content, unsafe_allow_html=True)
        else: st.caption("[BoÅŸ Mesaj]")

        if not is_user and content.strip(): # AI mesajÄ± eylemleri
             st.write("") # BoÅŸluk
             bcols = st.columns([0.85, 0.075, 0.075])
             with bcols[1]: # TTS
                 if st.session_state.tts_enabled and globals().get('tts_engine'):
                     if st.button("ğŸ”Š", key=f"tts_{chat_id}_{msg_idx}", help="Oku", use_container_width=True): speak(content)
             with bcols[2]: # Feedback
                 if st.button("âœï¸", key=f"fb_{chat_id}_{msg_idx}", help="Geri Bildirim", use_container_width=True):
                     st.session_state.current_message_id_for_feedback = f"{chat_id}_{msg_idx}"
                     prev_prompt = "[Ä°stem bulunamadÄ±]"
                     if msg_idx > 0 and st.session_state.all_chats[chat_id][msg_idx-1]['role'] == 'user':
                          prev_prompt = st.session_state.all_chats[chat_id][msg_idx-1]['parts']
                     st.session_state.last_user_prompt_for_feedback = prev_prompt
                     st.session_state.last_ai_response_for_feedback = content
                     st.session_state.show_feedback_comment_form = True
                     st.session_state.feedback_comment_input = ""
                     st.rerun()

def display_feedback_form_if_active():
    """Aktifse geri bildirim formunu gÃ¶sterir."""
    if st.session_state.get('show_feedback_comment_form') and st.session_state.current_message_id_for_feedback:
        st.markdown("---")
        fkey = f"fb_form_{st.session_state.current_message_id_for_feedback}"
        with st.form(key=fkey):
            st.markdown("#### YanÄ±t Geri Bildirimi")
            st.caption(f"**Ä°stem:** `{st.session_state.last_user_prompt_for_feedback[:80]}...`")
            st.caption(f"**YanÄ±t:** `{st.session_state.last_ai_response_for_feedback[:80]}...`")
            fb_type = st.radio("DeÄŸerlendirme:", ["ğŸ‘ BeÄŸendim", "ğŸ‘ BeÄŸenmedim"], horizontal=True, key=f"type_{fkey}", index=0 if st.session_state.last_feedback_type=='positive' else 1)
            comment = st.text_area("Yorum (isteÄŸe baÄŸlÄ±):", value=st.session_state.feedback_comment_input, key=f"cmt_{fkey}", height=100, placeholder="Neden?")
            st.session_state.feedback_comment_input = comment
            scol, ccol = st.columns(2)
            submitted = scol.form_submit_button("âœ… GÃ¶nder", use_container_width=True, type="primary")
            cancelled = ccol.form_submit_button("âŒ VazgeÃ§", use_container_width=True)

            if submitted:
                parsed_type = "positive" if fb_type == "ğŸ‘ BeÄŸendim" else "negative"
                st.session_state.last_feedback_type = parsed_type
                log_feedback(st.session_state.current_message_id_for_feedback, st.session_state.last_user_prompt_for_feedback, st.session_state.last_ai_response_for_feedback, parsed_type, comment)
                st.session_state.show_feedback_comment_form = False; st.session_state.current_message_id_for_feedback = None; st.session_state.feedback_comment_input = ""; st.rerun()
            elif cancelled:
                st.session_state.show_feedback_comment_form = False; st.session_state.current_message_id_for_feedback = None; st.session_state.feedback_comment_input = ""; st.rerun()
        st.markdown("---")

def display_chat_interface_main(main_col_ref):
    """Ana sohbet arayÃ¼zÃ¼nÃ¼ saÄŸ kolonda yÃ¶netir."""
    with main_col_ref:
        active_chat_id = st.session_state.get('active_chat_id')
        if active_chat_id is None:
            st.info("ğŸ’¬ BaÅŸlamak iÃ§in **'â• Yeni Sohbet'** butonuna tÄ±klayÄ±n veya listeden bir sohbet seÃ§in.", icon="ğŸ‘ˆ"); return

        current_history = st.session_state.all_chats.get(active_chat_id, [])
        chat_container = st.container(height=550, border=False)
        with chat_container:
            if not current_history: st.info(f"Merhaba {st.session_state.user_name}! Yeni sohbetinize hoÅŸ geldiniz.", icon="ğŸ‘‹")
            for i, msg in enumerate(current_history): display_chat_message_with_feedback(msg, i, active_chat_id)

        display_feedback_form_if_active() # Formu konteyner dÄ±ÅŸÄ±na taÅŸÄ±dÄ±k

        user_prompt = st.chat_input(f"{st.session_state.user_name}, ne sormak istersin?", key=f"input_{active_chat_id}")
        if user_prompt:
            user_msg = {'role': 'user', 'parts': user_prompt}
            st.session_state.all_chats[active_chat_id].append(user_msg)
            save_all_chats(st.session_state.all_chats)

            msg_id = f"msg_{st.session_state.message_id_counter}_{int(time.time())}"; st.session_state.message_id_counter += 1
            history_limit = 20 # Son N mesajÄ± gÃ¶nder
            history_for_model = st.session_state.all_chats[active_chat_id][-history_limit:-1] # Yeni eklenen hariÃ§

            with st.chat_message("assistant", avatar="â³"): placeholder = st.empty(); placeholder.markdown("ğŸ§  _DÃ¼ÅŸÃ¼nÃ¼yorum..._")

            ai_response, sender_name = get_hanogt_response_orchestrator(user_prompt, history_for_model, msg_id, active_chat_id, use_stream=st.session_state.gemini_stream_enabled)

            final_ai_msg = ""
            if st.session_state.gemini_stream_enabled and "Stream" in sender_name:
                 stream_container = placeholder; streamed_text = ""
                 try:
                     for chunk in ai_response:
                         if chunk.parts: text = "".join(p.text for p in chunk.parts if hasattr(p,'text')); streamed_text+=text; stream_container.markdown(streamed_text+"â–Œ"); time.sleep(0.01)
                     stream_container.markdown(streamed_text); final_ai_msg = streamed_text
                     log_interaction(user_prompt, final_ai_msg, "Gemini Stream", msg_id, active_chat_id) # Stream bitince logla
                 except Exception as e: error = f"Stream hatasÄ±: {e}"; stream_container.error(error); final_ai_msg=error; sender_name=f"{APP_NAME} (Stream HatasÄ±)"; log_interaction(user_prompt, final_ai_msg, "Stream HatasÄ±", msg_id, active_chat_id)
            else: placeholder.empty(); final_ai_msg = str(ai_response) # Loglama orkestratÃ¶rde yapÄ±ldÄ±

            ai_msg_data = {'role': 'model', 'parts': final_ai_msg, 'sender_display': sender_name}
            st.session_state.all_chats[active_chat_id].append(ai_msg_data)
            save_all_chats(st.session_state.all_chats)
            if st.session_state.tts_enabled and globals().get('tts_engine') and isinstance(final_ai_msg, str) and "Stream" not in sender_name: speak(final_ai_msg)
            st.rerun()


# --- UYGULAMA ANA AKIÅI ---
# BaÅŸlÄ±k ve Alt BaÅŸlÄ±k
st.markdown(f"<h1 style='text-align: center; color: #0078D4;'>{APP_NAME} {APP_VERSION}</h1>", unsafe_allow_html=True)
st.markdown(f"<p style='text-align: center; font-style: italic; color: #555;'>Yapay zeka destekli kiÅŸisel asistanÄ±nÄ±z</p>", unsafe_allow_html=True)

# Hata MesajlarÄ±
if gemini_init_error: st.error(gemini_init_error, icon="ğŸ›‘")
if supabase_error: st.warning(supabase_error, icon="ğŸ§±")
if tts_init_error and st.session_state.tts_enabled: st.toast(tts_init_error, icon="ğŸ”‡")

# --- GiriÅŸ EkranÄ± ---
if not st.session_state.show_main_app:
    st.subheader("ğŸ‘‹ Merhaba! BaÅŸlamadan Ã–nce...")
    lcols = st.columns([0.2, 0.6, 0.2])
    with lcols[1]:
        with st.form("login"):
            name = st.text_input("Size nasÄ±l hitap edelim?", placeholder="Ä°sminiz...", key="login_name")
            if st.form_submit_button("âœ¨ BaÅŸla", use_container_width=True, type="primary"):
                if name and name.strip():
                    st.session_state.user_name = name.strip()
                    st.session_state.show_main_app = True
                    st.session_state.greeting_message_shown = False
                    load_knowledge_from_file.clear()
                    if not st.session_state.active_chat_id and st.session_state.all_chats:
                         st.session_state.active_chat_id = list(st.session_state.all_chats.keys())[-1]
                    st.rerun()
                else: st.error("LÃ¼tfen geÃ§erli bir isim girin.")
else:
    # --- Ana Uygulama ---
    if not st.session_state.greeting_message_shown:
        st.success(f"HoÅŸ geldiniz {st.session_state.user_name}!", icon="ğŸ‰")
        st.session_state.greeting_message_shown = True

    left_col, main_col = st.columns([1, 3]) # Ana Layout

    display_chat_list_and_about(left_col) # Sol Kolon

    with main_col: # SaÄŸ Kolon
        display_settings_section() # Ayarlar

        # Mod SeÃ§imi
        st.markdown("#### Uygulama Modu")
        modes = { "YazÄ±lÄ± Sohbet": "ğŸ’¬", "Sesli Sohbet (Dosya)": "ğŸ¤", "YaratÄ±cÄ± StÃ¼dyo": "ğŸ¨", "GÃ¶rsel OluÅŸturucu": "ğŸ–¼ï¸" }
        keys = list(modes.keys()); idx = keys.index(st.session_state.app_mode) if st.session_state.app_mode in keys else 0
        selected = st.radio("Mod:", options=keys, index=idx, format_func=lambda k: f"{modes[k]} {k}", horizontal=True, label_visibility="collapsed", key="mode_radio")
        if selected != st.session_state.app_mode: st.session_state.app_mode = selected; st.rerun()
        st.markdown("<hr style='margin-top: 0.1rem; margin-bottom: 0.5rem;'>", unsafe_allow_html=True)

        # Mod Ä°Ã§eriÄŸi
        mode = st.session_state.app_mode
        if mode == "YazÄ±lÄ± Sohbet": display_chat_interface_main(main_col)
        elif mode == "Sesli Sohbet (Dosya)":
            # --- Sesli Sohbet Modu ---
            st.info("YanÄ±tlamamÄ± istediÄŸiniz ses dosyasÄ±nÄ± yÃ¼kleyin.", icon="ğŸ“¢")
            a_file = st.file_uploader("Ses DosyasÄ±:", type=['wav','mp3','ogg','flac','m4a'], label_visibility="collapsed", key="audio_up")
            if a_file:
                st.audio(a_file, format=a_file.type)
                active_id = st.session_state.get('active_chat_id')
                if not active_id: st.warning("Ã–nce bir sohbet seÃ§in/baÅŸlatÄ±n.", icon="âš ï¸")
                else:
                    audio_txt = None
                    with st.spinner(f"ğŸ”Š '{a_file.name}' iÅŸleniyor..."):
                        rec = sr.Recognizer()
                        try: # BytesIO ile dene
                            with sr.AudioFile(BytesIO(a_file.getvalue())) as src: audio_d = rec.record(src)
                            audio_txt = rec.recognize_google(audio_d, language="tr-TR")
                            st.success(f"**ğŸ™ï¸ AlgÄ±lanan:**\n> {audio_txt}")
                        except Exception as e: st.error(f"Ses iÅŸleme hatasÄ±: {e}"); print(f"ERROR: Audio proc failed: {e}")
                    if audio_txt: # YanÄ±t al ve ekle
                        u_msg={'role':'user','parts':f"(Ses: {a_file.name}) {audio_txt}"}; st.session_state.all_chats[active_id].append(u_msg)
                        msg_id=f"audio_{st.session_state.message_id_counter}_{int(time.time())}"; st.session_state.message_id_counter+=1
                        hist=st.session_state.all_chats[active_id][-20:-1] # Limit history
                        with st.spinner("ğŸ¤– YanÄ±t..."): ai_resp, sender = get_hanogt_response_orchestrator(audio_txt, hist, msg_id, active_id, False)
                        st.markdown(f"#### {sender} YanÄ±tÄ±:"); st.markdown(str(ai_resp))
                        if st.session_state.tts_enabled and globals().get('tts_engine'):
                            if st.button("ğŸ”Š Oku", key="spk_aud_resp"): speak(str(ai_resp))
                        ai_msg={'role':'model','parts':str(ai_resp),'sender_display':sender}; st.session_state.all_chats[active_id].append(ai_msg)
                        save_all_chats(st.session_state.all_chats); st.success("âœ… YanÄ±t sohbete eklendi!")
        elif mode == "YaratÄ±cÄ± StÃ¼dyo":
             # --- YaratÄ±cÄ± StÃ¼dyo Modu ---
            st.markdown("ğŸ’¡ Fikir verin, AI yaratÄ±cÄ± metin Ã¼retsin!")
            c_prompt = st.text_area("YaratÄ±cÄ±lÄ±k Tohumu:", key="cr_prompt", placeholder="Ã–rn: 'Uzaydaki kÃ¼tÃ¼phane'", height=100)
            cc1, cc2 = st.columns(2)
            len_p = cc1.selectbox("Uzunluk:", ["kÄ±sa", "orta", "uzun"], index=1, key="cr_len")
            sty_p = cc2.selectbox("Stil:", ["genel", "ÅŸiirsel", "hikaye"], index=0, key="cr_sty")
            if st.button("âœ¨ Ãœret!", key="cr_gen_btn", type="primary", use_container_width=True):
                if c_prompt and c_prompt.strip():
                    active_id=st.session_state.get('active_chat_id','creative_no_chat'); msg_id=f"cr_{st.session_state.message_id_counter}_{int(time.time())}"; st.session_state.message_id_counter+=1
                    final_resp, sender = None, f"{APP_NAME} (YaratÄ±cÄ±)"
                    if globals().get('gemini_model'): # Gemini dene
                        with st.spinner("âœ¨ Gemini ilham arÄ±yor..."):
                            sys_p=f"YaratÄ±cÄ± asistansÄ±n. Ä°stem: '{c_prompt}'. Stil: '{sty_p}', Uzunluk: '{len_p}'. Ã–zgÃ¼n metin oluÅŸtur."; gem_resp=get_gemini_response_cached(sys_p,[],False)
                            if isinstance(gem_resp,str) and not gem_resp.startswith(GEMINI_ERROR_PREFIX): final_resp,sender=gem_resp,f"{APP_NAME} (Gemini YaratÄ±cÄ±)"
                            else: st.toast("Gemini yaratÄ±cÄ± yanÄ±tÄ± alÄ±namadÄ±.",icon="â„¹ï¸")
                    if not final_resp: # Yerel Ã¼retici
                        with st.spinner("âœ¨ Hayal gÃ¼cÃ¼..."): final_resp=creative_response_generator(c_prompt,len_p,sty_p); new_w=advanced_word_generator(c_prompt.split()[0] if c_prompt else "kelime"); final_resp+=f"\n\n---\nğŸ”® **KelimatÃ¶r:** {new_w}"; sender=f"{APP_NAME} (Yerel YaratÄ±cÄ±)"
                    st.markdown(f"#### {sender} Ä°lhamÄ±:"); st.markdown(final_resp)
                    if st.session_state.tts_enabled and globals().get('tts_engine'):
                         if st.button("ğŸ”Š Dinle", key="spk_cr_resp"): speak(final_resp.split("ğŸ”® **KelimatÃ¶r:**")[0].strip())
                    log_interaction(c_prompt, final_resp, sender, msg_id, active_id); st.success("âœ¨ YanÄ±t oluÅŸturuldu!")
                    # if active_id != 'creative_no_chat': ... # Sohbete ekle?
                else: st.warning("LÃ¼tfen bir metin girin.", icon="âœï¸")
        elif mode == "GÃ¶rsel OluÅŸturucu":
            # --- GÃ¶rsel OluÅŸturucu Modu ---
            st.markdown("ğŸ¨ Hayalinizi tarif edin, AI (basitÃ§e) Ã§izsin!"); st.info("â„¹ï¸ Not: Sembolik Ã§izimler yapar.", icon="ğŸ’¡")
            img_prompt = st.text_input("GÃ¶rsel Tarifi:", key="img_prompt", placeholder="Ã–rn: 'Deniz kenarÄ±nda gÃ¼n batÄ±mÄ±'")
            if st.button("ğŸ–¼ï¸ OluÅŸtur!", key="gen_img_btn", type="primary", use_container_width=True):
                if img_prompt and img_prompt.strip():
                    with st.spinner("ğŸ–Œï¸ Ã‡iziliyor..."): img = generate_prompt_influenced_image(img_prompt)
                    st.image(img, caption=f"'{img_prompt[:60]}' yorumu", use_container_width=True)
                    try: # Ä°ndirme
                        buf=BytesIO(); img.save(buf,format="PNG"); img_bytes=buf.getvalue(); fname_p=re.sub(r'[^\w\s-]','',img_prompt.lower())[:30].replace(' ','_'); fname=f"hanogt_{fname_p or 'gorsel'}_{int(time.time())}.png"
                        st.download_button("ğŸ–¼ï¸ Ä°ndir (PNG)", data=img_bytes, file_name=fname, mime="image/png", use_container_width=True)
                        active_id=st.session_state.get('active_chat_id') # Sohbete ekle
                        if active_id and active_id in st.session_state.all_chats:
                            u_msg={'role':'user','parts':f"(GÃ¶rsel: {img_prompt})"}; ai_msg={'role':'model','parts':"(GÃ¶rsel oluÅŸturuldu - Ä°ndirme mevcut.)",'sender_display':f"{APP_NAME} (GÃ¶rsel)"}
                            st.session_state.all_chats[active_id].extend([u_msg,ai_msg]); save_all_chats(st.session_state.all_chats); st.info("Ä°stem sohbete eklendi.",icon="ğŸ’¾")
                    except Exception as e: st.error(f"Ä°ndirme hatasÄ±: {e}")
                else: st.warning("LÃ¼tfen bir tarif girin.", icon="âœï¸")

        # --- Alt Bilgi (Footer) ---
        st.markdown("<hr style='margin-top: 1rem; margin-bottom: 0.5rem;'>", unsafe_allow_html=True)
        fcols = st.columns(3)
        with fcols[0]: st.caption(f"KullanÄ±cÄ±: {st.session_state.get('user_name', 'N/A')}")
        with fcols[1]: st.caption(f"{APP_NAME} v{APP_VERSION} Â© {CURRENT_YEAR}")
        with fcols[2]:
             ai_stat="Aktif" if globals().get('gemini_model') else "Devre DÄ±ÅŸÄ±"; log_stat="Aktif" if globals().get('supabase') else "Devre DÄ±ÅŸÄ±"
             st.caption(f"AI: {ai_stat} | Log: {log_stat}", help=f"Model: {st.session_state.gemini_model_name}")

