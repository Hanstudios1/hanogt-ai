# app.py

# --- Gerekli KÃ¼tÃ¼phaneler ---
import streamlit as st
import requests
from bs4 import BeautifulSoup # lxml parser iÃ§in pip install lxml de gerekebilir
import wikipedia
import speech_recognition as sr
import pyttsx3
import random
import re
import os
import json
from PIL import Image, ImageDraw, ImageFont
import time
from io import BytesIO
from duckduckgo_search import DDGS
from urllib.parse import urlparse, unquote
import google.generativeai as genai
from datetime import datetime
import uuid # Daha benzersiz ID'ler iÃ§in

# tiktoken kÃ¼tÃ¼phanesi (isteÄŸe baÄŸlÄ±, token sayÄ±mÄ± iÃ§in)
# try:
#     import tiktoken
#     # tiktoken_encoder = tiktoken.get_encoding("cl100k_base") # Ã–rnek bir encoder
#     # tiktoken_encoder = tiktoken.encoding_for_model("gemini-1.5-flash-latest") # Modele gÃ¶re encoder
# except ImportError:
#     tiktoken = None
#     tiktoken_encoder = None
#     # st.toast("tiktoken kÃ¼tÃ¼phanesi bulunamadÄ±. Token sayÄ±mÄ± yaklaÅŸÄ±k olacaktÄ±r.", icon="âš ï¸")

try:
    from supabase import create_client, Client
    from postgrest import APIError as SupabaseAPIError # Supabase Ã¶zel hatalarÄ± iÃ§in
except ImportError:
    st.warning(
        "Supabase veya postgrest kÃ¼tÃ¼phanesi bulunamadÄ±. Loglama ve bazÄ± Supabase Ã¶zellikleri kÄ±sÄ±tlÄ± olabilir. "
        "`requirements.txt` dosyanÄ±zÄ± kontrol edin: `supabase`, `psycopg2-binary` (veya eÅŸdeÄŸeri) ve `postgrest` ekli olmalÄ±.",
        icon="â„¹ï¸"
    )
    create_client = None
    Client = None
    SupabaseAPIError = None # TanÄ±mlÄ± deÄŸilse None yapalÄ±m

# --- Sayfa YapÄ±landÄ±rmasÄ± (Ä°LK STREAMLIT KOMUTU OLMALI!) ---
st.set_page_config(
    page_title="Hanogt AI Pro+",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Sabitler ve YapÄ±landÄ±rma ---
APP_NAME = "Hanogt AI"
APP_VERSION = "4.8 Pro+"
CURRENT_YEAR = datetime.now().year
CHAT_HISTORY_FILE = "chat_history.json"
KNOWLEDGE_BASE_FILE = "knowledge_base.json"
DEFAULT_ERROR_MESSAGE = "ÃœzgÃ¼nÃ¼m, bir ÅŸeyler ters gitti. LÃ¼tfen biraz sonra tekrar deneyin."
REQUEST_TIMEOUT = 18
SCRAPE_MAX_CHARS = 3000
GEMINI_ERROR_PREFIX = "GeminiError:"
USER_AGENT = f"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 {APP_NAME}/{APP_VERSION}"
SUPABASE_TABLE_LOGS = "chat_logs"
SUPABASE_TABLE_FEEDBACK = "user_feedback"
FONT_FILE = "arial.ttf" # GÃ¶rsel oluÅŸturucu iÃ§in kullanÄ±lacak font dosyasÄ± adÄ±

# --- Bilgi TabanÄ± ---
knowledge_base_load_error = None

@st.cache_data(ttl=3600) # Bilgi tabanÄ±nÄ± 1 saat cache'le
def load_knowledge_from_file(filename=KNOWLEDGE_BASE_FILE):
    global knowledge_base_load_error
    dynamic_functions = {
        "saat kaÃ§": lambda: f"Åu an saat: {datetime.now().strftime('%H:%M:%S')}",
        "bugÃ¼n ayÄ±n kaÃ§Ä±": lambda: f"BugÃ¼n {datetime.now().strftime('%d %B %Y, %A')}",
        "tarih ne": lambda: f"BugÃ¼n {datetime.now().strftime('%d %B %Y, %A')}"
    }
    default_knowledge = {
        "merhaba": ["Merhaba!", "Selam!", "HoÅŸ geldin!", f"Size nasÄ±l yardÄ±mcÄ± olabilirim, {st.session_state.get('user_name', 'kullanÄ±cÄ±')}?"],
        "selam": ["Merhaba!", "Selam sana da!", "NasÄ±l gidiyor?"],
        "nasÄ±lsÄ±n": ["Ä°yiyim, teÅŸekkÃ¼rler! Siz nasÄ±lsÄ±nÄ±z?", "Harika hissediyorum, yardÄ±mcÄ± olmak iÃ§in buradayÄ±m!", "Her ÅŸey yolunda, sizin iÃ§in ne yapabilirim?"],
        "hanogt kimdir": [f"Ben {APP_NAME} ({APP_VERSION}), Streamlit ve Python ile geliÅŸtirilmiÅŸ bir yapay zeka asistanÄ±yÄ±m.", f"{APP_NAME} ({APP_VERSION}), sorularÄ±nÄ±zÄ± yanÄ±tlamak, metinler Ã¼retmek ve hatta basit gÃ¶rseller oluÅŸturmak iÃ§in tasarlandÄ±."],
        "teÅŸekkÃ¼r ederim": ["Rica ederim!", "Ne demek!", "YardÄ±mcÄ± olabildiÄŸime sevindim.", "Her zaman!"],
        "gÃ¶rÃ¼ÅŸÃ¼rÃ¼z": ["GÃ¶rÃ¼ÅŸmek Ã¼zere!", "HoÅŸÃ§a kal!", "Ä°yi gÃ¼nler dilerim!", "Tekrar beklerim!"],
        "adÄ±n ne": [f"Ben {APP_NAME}, versiyon {APP_VERSION}.", f"Bana {APP_NAME} diyebilirsiniz."],
        "ne yapabilirsin": ["SorularÄ±nÄ±zÄ± yanÄ±tlayabilir, metin Ã¶zetleyebilir, web'de arama yapabilir, yaratÄ±cÄ± metinler Ã¼retebilir ve basit gÃ¶rseller Ã§izebilirim.", "Size Ã§eÅŸitli konularda yardÄ±mcÄ± olabilirim. Ne merak ediyorsunuz?"],
        "saat kaÃ§": [dynamic_functions["saat kaÃ§"]],
        "bugÃ¼n ayÄ±n kaÃ§Ä±": [dynamic_functions["bugÃ¼n ayÄ±n kaÃ§Ä±"]],
        "tarih ne": [dynamic_functions["tarih ne"]],
        "hava durumu": ["ÃœzgÃ¼nÃ¼m, ÅŸu an iÃ§in gÃ¼ncel hava durumu bilgisi saÄŸlayamÄ±yorum. Bunun iÃ§in Ã¶zel bir hava durumu servisine gÃ¶z atabilirsiniz.", "Hava durumu servisim henÃ¼z aktif deÄŸil, ancak bu konuda bir geliÅŸtirme yapmayÄ± planlÄ±yorum!"]
    }

    try:
        if os.path.exists(filename):
            with open(filename, "r", encoding="utf-8") as f:
                loaded_kb = json.load(f)
            for key, value_list in loaded_kb.items():
                if isinstance(value_list, list):
                    for i, val_str in enumerate(value_list):
                        if val_str == "<function>" and key in dynamic_functions:
                            loaded_kb[key][i] = dynamic_functions[key]
            knowledge_base_load_error = None
            return loaded_kb
        else:
            knowledge_base_load_error = f"Bilgi tabanÄ± dosyasÄ± ({filename}) bulunamadÄ±. VarsayÄ±lan kullanÄ±lÄ±yor."
            return default_knowledge
    except json.JSONDecodeError:
        knowledge_base_load_error = f"Bilgi tabanÄ± dosyasÄ± ({filename}) hatalÄ± formatta. VarsayÄ±lan kullanÄ±lÄ±yor."
        return default_knowledge
    except Exception as e:
        knowledge_base_load_error = f"Bilgi tabanÄ± yÃ¼klenirken bilinmeyen bir hata oluÅŸtu: {e}. VarsayÄ±lan kullanÄ±lÄ±yor."
        return default_knowledge

KNOWLEDGE_BASE = load_knowledge_from_file()
if knowledge_base_load_error: st.toast(knowledge_base_load_error, icon="âš ï¸")

def kb_chatbot_response(query, knowledge):
    query_lower = query.lower().strip()
    if query_lower in knowledge:
        response_options = knowledge[query_lower]
        chosen_response = random.choice(response_options)
        return chosen_response() if callable(chosen_response) else chosen_response

    possible_responses = []
    for key, responses in knowledge.items():
        if key in query_lower:
            for resp_opt in responses:
                possible_responses.append(resp_opt() if callable(resp_opt) else resp_opt)
    if possible_responses: return random.choice(list(set(possible_responses)))

    query_words = set(re.findall(r'\b\w{3,}\b', query_lower))
    best_match_score = 0; best_responses_options = []
    for key, responses in knowledge.items():
        key_words = set(re.findall(r'\b\w{3,}\b', key.lower()))
        if not key_words: continue
        common_words = query_words.intersection(key_words)
        score = len(common_words) / len(key_words) if len(key_words) > 0 else 0
        if score > 0.6:
            if score > best_match_score:
                best_match_score = score; best_responses_options = responses
            elif score == best_match_score: best_responses_options.extend(responses)
    if best_responses_options:
        chosen_response = random.choice(list(set(best_responses_options)))
        return chosen_response() if callable(chosen_response) else chosen_response
    return None

# --- API AnahtarÄ± ve Gemini YapÄ±landÄ±rmasÄ± ---
gemini_model = None
gemini_init_error_global = None

def initialize_gemini_model():
    global gemini_init_error_global
    api_key_local = st.secrets.get("GOOGLE_API_KEY")
    if not api_key_local:
        gemini_init_error_global = "ğŸ›‘ Google API AnahtarÄ± Secrets'ta (st.secrets) bulunamadÄ±! Gemini Ã¶zellikleri kÄ±sÄ±tlÄ± olacak."
        return None
    try:
        genai.configure(api_key=api_key_local)
        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        ]
        model = genai.GenerativeModel(
            model_name=st.session_state.get('gemini_model_name', 'gemini-1.5-flash-latest'),
            safety_settings=safety_settings,
            generation_config=genai.types.GenerationConfig(
                temperature=st.session_state.get('gemini_temperature', 0.7),
                top_p=st.session_state.get('gemini_top_p', 0.95),
                top_k=st.session_state.get('gemini_top_k', 40),
                max_output_tokens=st.session_state.get('gemini_max_tokens', 4096)
            )
        )
        gemini_init_error_global = None
        return model
    except Exception as e:
        gemini_init_error_global = f"ğŸ›‘ Gemini yapÄ±landÄ±rma hatasÄ±: {e}. LÃ¼tfen API anahtarÄ±nÄ±zÄ± ve internet baÄŸlantÄ±nÄ±zÄ± kontrol edin."
        return None

# --- Supabase Ä°stemcisini BaÅŸlatma ---
supabase = None
supabase_error_global = None

@st.cache_resource(ttl=3600)
def init_supabase_client_cached():
    global supabase_error_global
    supabase_url_local = st.secrets.get("SUPABASE_URL")
    supabase_key_local = st.secrets.get("SUPABASE_SERVICE_KEY")
    if not create_client:
        supabase_error_global = "Supabase kÃ¼tÃ¼phanesi yÃ¼klenemedi. Loglama Ã§alÄ±ÅŸmayacak."
        return None
    if not supabase_url_local or not supabase_key_local:
        supabase_error_global = "Supabase URL veya Service Key Secrets'ta bulunamadÄ±! Loglama Ã¶zelliÄŸi devre dÄ±ÅŸÄ± kalacak."
        return None
    try:
        client = create_client(supabase_url_local, supabase_key_local)
        supabase_error_global = None
        return client
    except Exception as e:
        error_msg_supabase = f"Supabase baÄŸlantÄ± hatasÄ±: {e}. Loglama yapÄ±lamayacak."
        if "failed to parse" in str(e).lower() or "invalid url" in str(e).lower():
            error_msg_supabase += " LÃ¼tfen Supabase URL'inizin doÄŸru formatta olduÄŸundan emin olun (Ã¶rn: https://xyz.supabase.co)."
        elif "invalid key" in str(e).lower():
            error_msg_supabase += " LÃ¼tfen Supabase Service Key'inizin doÄŸru olduÄŸundan emin olun."
        supabase_error_global = error_msg_supabase
        return None

# --- YARDIMCI FONKSÄ°YONLAR ---
def _get_session_id():
    if 'session_id' not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())
    return st.session_state.session_id

tts_engine = None
tts_init_error_global = None

@st.cache_resource
def init_tts_engine_cached():
    global tts_init_error_global
    try:
        engine = pyttsx3.init()
        tts_init_error_global = None
        return engine
    except Exception as e:
        tts_init_error_global = f"âš ï¸ Metin okuma (TTS) motoru baÅŸlatÄ±lamadÄ±: {e}. Bu Ã¶zellik kullanÄ±lamayacak."
        return None

def speak(text_to_speak):
    current_tts_engine = globals().get('tts_engine')
    if not current_tts_engine or not st.session_state.get('tts_enabled', True):
        if current_tts_engine: st.toast("Metin okuma Ã¶zelliÄŸi kapalÄ±.", icon="ğŸ”‡")
        else: st.toast("Metin okuma motoru aktif deÄŸil veya baÅŸlatÄ±lamadÄ±.", icon="ğŸ”‡")
        return
    try:
        current_tts_engine.say(text_to_speak)
        current_tts_engine.runAndWait()
    except RuntimeError as re_tts:
        st.warning(f"KonuÅŸma motorunda bir Ã§alÄ±ÅŸma zamanÄ± sorunu oluÅŸtu: {re_tts}", icon="ğŸ”Š")
    except Exception as e_tts:
        st.error(f"KonuÅŸma sÄ±rasÄ±nda beklenmedik bir hata oluÅŸtu: {e_tts}", icon="ğŸ”Š")

def _clean_text(text: str) -> str:
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'\n\s*\n', '\n\n', text)
    return text.strip()

def scrape_url_content(url: str, timeout: int = REQUEST_TIMEOUT, max_chars: int = SCRAPE_MAX_CHARS) -> str | None:
    st.toast(f"ğŸŒ '{urlparse(url).netloc}' sayfasÄ±ndan iÃ§erik alÄ±nÄ±yor...", icon="â³")
    try:
        parsed_url = urlparse(url)
        if not all([parsed_url.scheme, parsed_url.netloc]) or parsed_url.scheme not in ['http', 'https']:
            st.warning(f"GeÃ§ersiz URL formatÄ±: {url}", icon="ğŸ”—"); return None
        headers = {
            'User-Agent': USER_AGENT,
            'Accept-Language': 'tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Connection': 'keep-alive'
        }
        response = requests.get(url, headers=headers, timeout=timeout, allow_redirects=True, stream=True)
        response.raise_for_status()

        content_type = response.headers.get('content-type', '').lower()
        if 'html' not in content_type:
            st.info(f"URL HTML iÃ§eriÄŸi deÄŸil ('{content_type}' tipinde). KazÄ±ma atlanÄ±yor: {url}", icon="ğŸ“„"); return None

        html_content = ""; content_length_processed = 0
        max_html_size_to_process = max_chars * 10
        for chunk in response.iter_content(chunk_size=16384, decode_unicode=True, errors='ignore'):
            html_content += chunk
            content_length_processed += len(chunk.encode('utf-8', 'ignore'))
            if content_length_processed > max_html_size_to_process:
                st.warning(f"HTML iÃ§eriÄŸi Ã§ok bÃ¼yÃ¼k ({content_length_processed / 1024:.0f}KB), ilk kÄ±smÄ± iÅŸlenecek.", icon="âœ‚ï¸"); break
        response.close()

        soup = BeautifulSoup(html_content, 'lxml')
        for element_to_remove in soup(["script", "style", "nav", "footer", "aside", "form", "button", "iframe", "header", "noscript", "link", "meta", "img", "svg", "video", "audio", "figure", "figcaption"]):
            element_to_remove.decompose()

        potential_content_parts = []
        content_selectors = [
            'article[class*="content"]', 'article[class*="post"]', 'article[class*="entry"]',
            'main[class*="content"]', 'main[id*="content"]',
            'div[class*="post-body"]', 'div[class*="article-body"]', 'div[class*="entry-content"]',
            'div[itemprop="articleBody"]',
            'article', 'main', '.content', '.post-content', '.entry-content', 'section[role="main"]'
        ]
        content_found_flag = False
        for selector in content_selectors:
            elements_found = soup.select(selector)
            if elements_found:
                container_element = elements_found[0]
                paragraphs_and_divs = container_element.find_all(['p', 'div'], recursive=False, limit=35)
                temp_content_list = []
                for p_or_div in paragraphs_and_divs:
                    text_from_element = _clean_text(p_or_div.get_text(separator=' ', strip=True))
                    if len(text_from_element) > 100 and (text_from_element.count('.') + text_from_element.count('!') + text_from_element.count('?')) >= 1:
                        temp_content_list.append(text_from_element)
                if len(" ".join(temp_content_list)) > 500:
                    potential_content_parts = temp_content_list
                    content_found_flag = True; break
        
        if not content_found_flag:
            body_text_content = _clean_text(soup.body.get_text(separator=' ', strip=True) if soup.body else "")
            if len(body_text_content) > 300:
                st.toast("Ã–zel iÃ§erik alanlarÄ± bulunamadÄ±, sayfanÄ±n genel metni kullanÄ±ldÄ±.", icon="â„¹ï¸")
                potential_content_parts = [body_text_content]
            else:
                st.toast("Sayfada anlamlÄ± metin iÃ§eriÄŸi bulunamadÄ±.", icon="ğŸ“„"); return None

        full_text_content = "\n\n".join(potential_content_parts)
        cleaned_text_content = _clean_text(full_text_content)
        if not cleaned_text_content: return None

        final_text_output = cleaned_text_content[:max_chars]
        if len(cleaned_text_content) > max_chars: final_text_output += "..."
        st.toast(f"'{urlparse(url).netloc}' sayfasÄ±nÄ±n iÃ§eriÄŸi baÅŸarÄ±yla alÄ±ndÄ±.", icon="âœ…")
        return final_text_output

    except requests.exceptions.HTTPError as e_http: st.toast(f"âš ï¸ Sayfa alÄ±nÄ±rken HTTP hatasÄ± ({e_http.response.status_code}): {url}", icon='ğŸŒ')
    except requests.exceptions.Timeout: st.toast(f"âš ï¸ Sayfa alÄ±nÄ±rken zaman aÅŸÄ±mÄ± oluÅŸtu: {url}", icon='â³')
    except requests.exceptions.ConnectionError: st.toast(f"âš ï¸ Sayfa baÄŸlantÄ± hatasÄ± (siteye ulaÅŸÄ±lamÄ±yor olabilir): {url}", icon='ğŸ”Œ')
    except requests.exceptions.RequestException as e_req: st.toast(f"âš ï¸ Sayfa alÄ±nÄ±rken genel bir aÄŸ hatasÄ±: {e_req}", icon='ğŸŒ')
    except Exception as e_scrape: st.toast(f"âš ï¸ Sayfa iÃ§eriÄŸi iÅŸlenirken beklenmedik bir hata: {e_scrape}", icon='âš™ï¸')
    return None

def search_web(query: str) -> str | None:
    st.toast(f"ğŸ” '{query}' iÃ§in web'de arama yapÄ±lÄ±yor...", icon="â³")
    wikipedia.set_lang("tr")
    try:
        summary = wikipedia.summary(query, sentences=5, auto_suggest=True, redirect=True)
        st.toast(f"â„¹ï¸ '{query}' iÃ§in Wikipedia'dan bilgi bulundu.", icon="âœ…")
        return f"**Wikipedia'dan ({query}):**\n\n{_clean_text(summary)}"
    except wikipedia.exceptions.PageError:
        st.toast(f"â„¹ï¸ '{query}' iÃ§in Wikipedia'da doÄŸrudan eÅŸleÅŸen bir sayfa bulunamadÄ±.", icon="ğŸ¤·")
    except wikipedia.exceptions.DisambiguationError as e_disamb:
        options_text = "\n\nWikipedia'da olasÄ± baÅŸlÄ±klar (ilk 3):\n" + "\n".join([f"- {opt}" for opt in e_disamb.options[:3]])
        st.toast(f"Wikipedia'da '{query}' iÃ§in birden fazla anlam bulundu. Daha spesifik bir arama yapabilirsiniz.", icon="ğŸ“š")
        return f"**Wikipedia'da Birden Fazla Anlam Bulundu ({query}):**\n{str(e_disamb).splitlines()[0]}{options_text}"
    except Exception: pass

    ddg_result_text = None; ddg_url_source = None
    try:
        with DDGS(headers={'User-Agent': USER_AGENT}, timeout=REQUEST_TIMEOUT) as ddgs_search:
            results = list(ddgs_search.text(query, region='tr-tr', safesearch='moderate', max_results=3))
            if results:
                for res_item in results:
                    snippet_text = res_item.get('body')
                    temp_source_url = res_item.get('href')
                    if snippet_text and temp_source_url:
                        decoded_url_source = unquote(temp_source_url)
                        st.toast(f"â„¹ï¸ DuckDuckGo'dan '{urlparse(decoded_url_source).netloc}' iÃ§in Ã¶zet bulundu.", icon="ğŸ¦†")
                        ddg_result_text = f"**Web Ã–zeti (DuckDuckGo - {urlparse(decoded_url_source).netloc}):**\n\n{_clean_text(snippet_text)}\n\nKaynak: {decoded_url_source}"
                        ddg_url_source = decoded_url_source; break
    except Exception: pass

    if ddg_url_source:
        scraped_content_from_url = scrape_url_content(ddg_url_source)
        if scraped_content_from_url:
            return f"**Web SayfasÄ±ndan DetaylÄ± Bilgi ({urlparse(ddg_url_source).netloc}):**\n\n{scraped_content_from_url}\n\nTam Ä°Ã§erik Ä°Ã§in Kaynak Adres: {ddg_url_source}"
        elif ddg_result_text:
             st.toast("â„¹ï¸ Sayfa iÃ§eriÄŸi kazÄ±namadÄ±, DuckDuckGo Ã¶zeti kullanÄ±lÄ±yor.", icon="ğŸ“")
             return ddg_result_text
        else:
            return f"DetaylÄ± bilgi iÃ§in ÅŸu adresi ziyaret edebilirsiniz: {ddg_url_source}"

    if ddg_result_text:
        return ddg_result_text

    st.toast(f"'{query}' iÃ§in web'de kapsamlÄ± bir yanÄ±t bulunamadÄ±.", icon="âŒ"); return None

@st.cache_data(ttl=86400)
def load_chat_history_cached(file_path: str = CHAT_HISTORY_FILE) -> list:
    if os.path.exists(file_path):
        try:
            with open(file_path, "r", encoding="utf-8") as f: content_read = f.read()
            if content_read and content_read.strip(): return json.loads(content_read)
            else: return []
        except json.JSONDecodeError:
            st.error(f"Sohbet geÃ§miÅŸi dosyasÄ± ({file_path}) bozuk veya hatalÄ± formatta. Yeni bir geÃ§miÅŸ baÅŸlatÄ±lÄ±yor.")
            try: os.rename(file_path, f"{file_path}.backup_{int(time.time())}")
            except OSError: pass
            return []
        except Exception as e_load_hist:
            st.error(f"Sohbet geÃ§miÅŸi dosyasÄ± ({file_path}) yÃ¼klenirken bir hata oluÅŸtu: {e_load_hist}"); return []
    return []

def save_chat_history(history_to_save: list, file_path: str = CHAT_HISTORY_FILE):
    try:
        with open(file_path, "w", encoding="utf-8") as f_save:
            json.dump(history_to_save, f_save, ensure_ascii=False, indent=2)
    except Exception as e_save_hist: st.error(f"Sohbet geÃ§miÅŸi kaydedilemedi: {e_save_hist}")

def get_gemini_response_cached(prompt_text: str, chat_history_for_gemini_model: list[dict], stream_output: bool = False) -> str | object:
    current_gemini_model = globals().get('gemini_model')
    if not current_gemini_model: return f"{GEMINI_ERROR_PREFIX} Gemini modeli aktif deÄŸil veya baÅŸlatÄ±lamadÄ±."
    try:
        chat_session = current_gemini_model.start_chat(history=chat_history_for_gemini_model)
        response_from_gemini = chat_session.send_message(prompt_text, stream=stream_output)

        if stream_output: return response_from_gemini
        else:
            if not response_from_gemini.parts:
                if hasattr(response_from_gemini, 'prompt_feedback') and response_from_gemini.prompt_feedback.block_reason:
                    block_reason = response_from_gemini.prompt_feedback.block_reason
                    block_message = response_from_gemini.prompt_feedback.block_reason_message or "Ek detay verilmedi."
                    warning_msg = f"Gemini yanÄ±tÄ± gÃ¼venlik nedeniyle engellendi: {block_reason}. Detay: {block_message}"
                    st.warning(warning_msg, icon="ğŸ›¡ï¸"); return f"{GEMINI_ERROR_PREFIX} {warning_msg}"
                elif response_from_gemini.candidates and hasattr(response_from_gemini.candidates[0], 'finish_reason') and response_from_gemini.candidates[0].finish_reason != 'STOP':
                    finish_reason_gemini = response_from_gemini.candidates[0].finish_reason
                    st.warning(f"Gemini yanÄ±tÄ± tam olarak oluÅŸturulamadÄ±. Sebep: {finish_reason_gemini}", icon="âš ï¸"); return f"{GEMINI_ERROR_PREFIX} YanÄ±t tam deÄŸil. Sebep: {finish_reason_gemini}."
                else:
                    st.warning(f"Gemini'dan boÅŸ veya beklenmedik bir yanÄ±t alÄ±ndÄ±: {response_from_gemini}", icon="â‰ï¸"); return f"{GEMINI_ERROR_PREFIX} BoÅŸ veya anlaÅŸÄ±lamayan yanÄ±t."
            return "".join(part.text for part in response_from_gemini.parts if hasattr(part, 'text'))

    except genai.types.BlockedPromptException as bpe_gemini:
        st.error(f"Gemini Ä°stem Engelleme HatasÄ±: GÃ¶nderdiÄŸiniz istem gÃ¼venlik filtrelerini tetikledi. LÃ¼tfen isteminizi gÃ¶zden geÃ§irin. Detay: {bpe_gemini}", icon="ğŸ›¡ï¸")
        return f"{GEMINI_ERROR_PREFIX} Ä°stem gÃ¼venlik nedeniyle engellendi."
    except genai.types.StopCandidateException as sce_gemini:
        st.error(f"Gemini YanÄ±t Kesintisi: YanÄ±t oluÅŸturulurken beklenmedik bir durma yaÅŸandÄ±. Detay: {sce_gemini}", icon="ğŸ›‘")
        return f"{GEMINI_ERROR_PREFIX} YanÄ±t oluÅŸturulurken kesildi."
    except requests.exceptions.ReadTimeout:
        st.error("Gemini API isteÄŸi zaman aÅŸÄ±mÄ±na uÄŸradÄ± (ReadTimeout). LÃ¼tfen internet baÄŸlantÄ±nÄ±zÄ± kontrol edip tekrar deneyin.", icon="â³")
        return f"{GEMINI_ERROR_PREFIX} API okuma zaman aÅŸÄ±mÄ±."
    except Exception as e_gemini_api:
        error_message_gemini = f"Gemini API ile iletiÅŸimde bir hata oluÅŸtu: {e_gemini_api}"
        st.error(error_message_gemini, icon="ğŸ“¡")
        if "API key not valid" in str(e_gemini_api).lower(): return f"{GEMINI_ERROR_PREFIX} Google API AnahtarÄ± geÃ§ersiz veya hatalÄ±."
        elif "Deadline Exceeded" in str(e_gemini_api).lower() or "504" in str(e_gemini_api).lower() or "timeout" in str(e_gemini_api).lower():
            return f"{GEMINI_ERROR_PREFIX} API isteÄŸi zaman aÅŸÄ±mÄ±na uÄŸradÄ±. LÃ¼tfen tekrar deneyin."
        return f"{GEMINI_ERROR_PREFIX} API ile iletiÅŸim kurulamadÄ±: {str(e_gemini_api)[:150]}..."

def log_to_supabase(table_name: str, data_to_log: dict):
    current_supabase_client = globals().get('supabase')
    if not current_supabase_client:
        print(f"INFO: Supabase istemcisi None, '{table_name}' tablosuna loglama atlanÄ±yor.")
        return False
    try:
        insert_result_supabase = current_supabase_client.table(table_name).insert(data_to_log).execute()
        if hasattr(insert_result_supabase, 'data') and not insert_result_supabase.data and hasattr(insert_result_supabase, 'error') and insert_result_supabase.error:
            error_info_supabase = insert_result_supabase.error; error_message_log = str(error_info_supabase)
            if SupabaseAPIError and isinstance(error_info_supabase, SupabaseAPIError):
               error_message_log = f"Supabase API HatasÄ± - Kod: {error_info_supabase.code}, Mesaj: {error_info_supabase.message}, Detay: {error_info_supabase.details}, Ä°pucu: {error_info_supabase.hint}"
            st.toast(f"âš ï¸ '{table_name}' logu Supabase'e kaydedilemedi: {error_message_log}", icon="ğŸ’¾")
            print(f"WARN: Supabase '{table_name}' tablosuna insert iÅŸlemi baÅŸarÄ±sÄ±z. Hata: {error_message_log}")
            return False
        elif not insert_result_supabase.data and not hasattr(insert_result_supabase, 'error'):
             st.toast(f"âš ï¸ '{table_name}' logu Supabase'e kaydedildi ancak sunucudan boÅŸ yanÄ±t alÄ±ndÄ±.", icon="ğŸ’¾")
             print(f"WARN: Supabase '{table_name}' insert baÅŸarÄ±lÄ± ancak dÃ¶nen data boÅŸ. Result: {insert_result_supabase}")
             return True
        return True
    except SupabaseAPIError as e_supabase_api:
        print(f"ERROR: Supabase API hatasÄ± ('{table_name}'): {e_supabase_api.message} (Kod: {e_supabase_api.code})")
        st.error(f"Supabase loglama sÄ±rasÄ±nda API hatasÄ±: {e_supabase_api.message}")
        return False
    except Exception as e_supabase_log:
        print(f"ERROR: Supabase '{table_name}' tablosuna loglama sÄ±rasÄ±nda kritik bir hata: {e_supabase_log}")
        st.error(f"Supabase '{table_name}' tablosuna loglama sÄ±rasÄ±nda kritik bir hata oluÅŸtu! Detay: {type(e_supabase_log).__name__}: {e_supabase_log}")
        return False

def log_interaction(user_prompt_text: str, ai_response_text: str, response_source_info: str, message_unique_id: str):
    interaction_log_data = {
        "user_prompt": user_prompt_text, "ai_response": ai_response_text, "response_source": response_source_info,
        "user_name": st.session_state.get('user_name', 'Bilinmiyor'),
        "session_id": _get_session_id(), "app_version": APP_VERSION, "message_id": message_unique_id
    }
    return log_to_supabase(SUPABASE_TABLE_LOGS, interaction_log_data)

def log_feedback(message_unique_id: str, user_prompt_text: str, ai_response_text: str, feedback_category: str, user_comment: str = ""):
    feedback_log_data = {
        "message_id": message_unique_id, "user_prompt": user_prompt_text, "ai_response": ai_response_text,
        "feedback_type": feedback_category, "comment": user_comment,
        "user_name": st.session_state.get('user_name', 'Bilinmiyor'),
        "session_id": _get_session_id(), "app_version": APP_VERSION
    }
    if log_to_supabase(SUPABASE_TABLE_FEEDBACK, feedback_log_data):
        st.toast(f"Geri bildiriminiz iÃ§in teÅŸekkÃ¼r ederiz!", icon="ğŸ’Œ"); return True
    else: st.toast(f"ÃœzgÃ¼nÃ¼z, geri bildiriminiz gÃ¶nderilemedi. LÃ¼tfen daha sonra tekrar deneyin.", icon="ğŸ˜”"); return False

def get_hanogt_response_orchestrator(user_prompt_text: str, chat_history_for_model_processing: list[dict], current_message_unique_id: str, use_stream_output:bool = False) -> tuple[str | object, str]:
    ai_response_content = None; ai_sender_name = APP_NAME

    kb_functional_response = kb_chatbot_response(user_prompt_text, KNOWLEDGE_BASE)
    if kb_functional_response and callable(kb_functional_response):
        try:
            ai_response_content = kb_functional_response()
            ai_sender_name = f"{APP_NAME} (Fonksiyonel)"
            log_interaction(user_prompt_text, ai_response_content, ai_sender_name, current_message_unique_id)
            return ai_response_content, ai_sender_name
        except Exception as e_kb_func:
            st.error(f"Bilgi tabanÄ± fonksiyonel yanÄ±tÄ± iÅŸlenirken bir hata oluÅŸtu: {e_kb_func}")
            ai_response_content = None

    current_gemini_model = globals().get('gemini_model')
    if current_gemini_model:
        ai_response_content = get_gemini_response_cached(user_prompt_text, chat_history_for_model_processing, stream=use_stream_output)
        if ai_response_content:
            if use_stream_output: return ai_response_content, f"{APP_NAME} (Gemini Stream)"
            elif not (isinstance(ai_response_content, str) and ai_response_content.startswith(GEMINI_ERROR_PREFIX)):
                ai_sender_name = f"{APP_NAME} (Gemini)"
                log_interaction(user_prompt_text, str(ai_response_content), ai_sender_name, current_message_unique_id)
                return str(ai_response_content), ai_sender_name
            ai_response_content = None

    if not ai_response_content:
        st.toast("ğŸ“š Bilgi tabanÄ± kontrol ediliyor...", icon="ğŸ—‚ï¸")
        kb_static_response = kb_chatbot_response(user_prompt_text, KNOWLEDGE_BASE)
        if kb_static_response and not callable(kb_static_response):
            ai_response_content = kb_static_response; ai_sender_name = f"{APP_NAME} (Bilgi TabanÄ±)"
            log_interaction(user_prompt_text, ai_response_content, ai_sender_name, current_message_unique_id)
            return ai_response_content, ai_sender_name

    if not ai_response_content:
        if len(user_prompt_text.split()) > 2 and \
           ("?" in user_prompt_text or \
            any(keyword in user_prompt_text.lower() for keyword in ["nedir", "kimdir", "nasÄ±l", "ne zaman", "nerede", "anlamÄ±", "hakkÄ±nda bilgi", "araÅŸtÄ±r", "son durum"])):
            st.toast("ğŸŒ Web'de arama yapÄ±lÄ±yor...", icon="ğŸ”")
            web_search_response = search_web(user_prompt_text)
            if web_search_response:
                ai_response_content = web_search_response; ai_sender_name = f"{APP_NAME} (Web Arama)"
                log_interaction(user_prompt_text, ai_response_content, ai_sender_name, current_message_unique_id)
                return ai_response_content, ai_sender_name
        else:
            st.toast("â„¹ï¸ KÄ±sa veya genel bir istem olduÄŸu iÃ§in web aramasÄ± atlandÄ±.", icon="â©")

    if not ai_response_content:
        st.toast("ğŸ¤” ÃœzgÃ¼nÃ¼m, bu isteÄŸiniz iÃ§in uygun bir yanÄ±t bulamadÄ±m.", icon="ğŸ¤·")
        default_responses_list = [
            f"ÃœzgÃ¼nÃ¼m {st.session_state.get('user_name', 'dostum')}, bu konuda size ÅŸu an yardÄ±mcÄ± olamÄ±yorum. FarklÄ± bir ÅŸekilde sorabilir misiniz?",
            "Bu soruyu tam olarak anlayamadÄ±m. Daha basit veya farklÄ± kelimelerle tekrar ifade edebilir misiniz?",
            "Bu konuda ÅŸu anda bir fikrim yok maalesef. BaÅŸka bir konuda yardÄ±mcÄ± olabilirim belki?",
            "YanÄ±t veremiyorum ama her geÃ§en gÃ¼n yeni ÅŸeyler Ã¶ÄŸrenmeye devam ediyorum! BaÅŸka bir sorunuz var mÄ±?",
        ]
        ai_response_content = random.choice(default_responses_list); ai_sender_name = f"{APP_NAME} (VarsayÄ±lan)"
        log_interaction(user_prompt_text, ai_response_content, ai_sender_name, current_message_unique_id)

    return ai_response_content, ai_sender_name

def creative_response_generator(user_prompt_text: str, length_preference: str = "orta", style_preference: str = "genel") -> str:
    style_templates_map = {
        "genel": ["FarklÄ± bir bakÄ±ÅŸ aÃ§Ä±sÄ±yla ele alÄ±rsak: {}", "Hayal gÃ¼cÃ¼mÃ¼zÃ¼ serbest bÄ±rakalÄ±m: {}", "AklÄ±ma ÅŸÃ¶yle bir fikir geldi: {}"],
        "ÅŸiirsel": ["Kalbimden dÃ¶kÃ¼len mÄ±sralar ÅŸÃ¶yle fÄ±sÄ±ldar: {}", "SÃ¶zcÃ¼klerin dansÄ±yla, bir ÅŸiir doÄŸar: {}", "DuygularÄ±n ritmiyle, mÄ±sralar canlanÄ±r: {}"],
        "hikaye": ["Bir zamanlar, uzak diyarlarda baÅŸlayan bir hikaye bu: {}", "Perde aralanÄ±r ve sahne sizin hayal gÃ¼cÃ¼nÃ¼zÃ¼ndÃ¼r: {}", "Her ÅŸey o bÃ¼yÃ¼lÃ¼ gÃ¼nde baÅŸladÄ±: {}"]
    }
    selected_templates = style_templates_map.get(style_preference, style_templates_map["genel"])
    base_creative_idea = generate_new_idea_creative(user_prompt_text, style_preference)

    if length_preference == "kÄ±sa":
        sentences = base_creative_idea.split('.')
        base_creative_idea = ". ".join(sentences[:max(1, len(sentences) // 3)]).strip()
        if base_creative_idea and not base_creative_idea.endswith('.'): base_creative_idea += "."
    elif length_preference == "uzun":
        additional_idea = generate_new_idea_creative(user_prompt_text[::-1] + " devamÄ±", style_preference)
        base_creative_idea += f"\n\nBu konuyu daha da derinleÅŸtirecek olursak, belki de {additional_idea} diyebiliriz. Hayal gÃ¼cÃ¼nÃ¼n sÄ±nÄ±rÄ± yoktur!"

    return random.choice(selected_templates).format(base_creative_idea)

def generate_new_idea_creative(seed_prompt_text: str, style:str = "genel") -> str:
    elements_list = ["zaman kristalleri", "psiÅŸik ormanlar", "rÃ¼ya mimarisi eserleri", "kuantum kÃ¶pÃ¼ÄŸÃ¼ okyanuslarÄ±", "gÃ¶lge enerjisi dansÄ±", "yankÄ±lanan anÄ±larÄ±n fÄ±sÄ±ltÄ±sÄ±", "kayÄ±p yÄ±ldÄ±z haritalarÄ±nÄ±n rehberliÄŸi", "fraktal dÃ¼ÅŸÃ¼nce kalÄ±plarÄ±", "kozmik senfoninin yankÄ±larÄ±", "unutulmuÅŸ kehanetlerin gizemi", "eterik varlÄ±klarÄ±n ÅŸarkÄ±larÄ±"]
    actions_list = ["dokur", "Ã§Ã¶zer", "yansÄ±tÄ±r", "inÅŸa eder", "fÄ±sÄ±ldar", "dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r", "keÅŸfeder", "haritalarÄ±nÄ± Ã§izer", "ile baÄŸlantÄ± kurar", "Ã§aÄŸÄ±rÄ±r", "ÅŸekillendirir"]
    outcomes_list = ["kaderin gizli ipliklerini", "varoluÅŸun unutulmuÅŸ kodunu", "bilincin en derin sÄ±nÄ±rlarÄ±nÄ±", "kayÄ±p uygarlÄ±klarÄ±n kadim sÄ±rlarÄ±nÄ±", "evrenin ebedi melodisini", "gerÃ§ekliÄŸin Ã§ok boyutlu dokusunu", "saklÄ± kalmÄ±ÅŸ sonsuz potansiyelleri", "yepyeni bir Ã§aÄŸÄ±n ÅŸafaÄŸÄ±nÄ±", "ruhun aydÄ±nlanma yolculuÄŸunu"]
    
    prompt_words = re.findall(r'\b\w{3,}\b', seed_prompt_text.lower())
    seed_elements_for_idea = random.sample(prompt_words, k=min(len(prompt_words), 2)) if prompt_words else ["gizemli", "bir Ä±ÅŸÄ±k"]
    
    if style == "ÅŸiirsel":
        return f"{random.choice(elements_list).capitalize()} arasÄ±nda sÃ¼zÃ¼lÃ¼rken, {seed_elements_for_idea[0]} fÄ±sÄ±ldar usulca, {random.choice(outcomes_list)}."
    elif style == "hikaye":
        return f"{' '.join(seed_elements_for_idea).capitalize()} {random.choice(actions_list)} ve {random.choice(elements_list)} kullanarak, sonunda {random.choice(outcomes_list)} keÅŸfeder."
    return f"{' '.join(seed_elements_for_idea).capitalize()} {random.choice(actions_list)} ve {random.choice(elements_list)} aracÄ±lÄ±ÄŸÄ±yla {random.choice(outcomes_list)}."

def advanced_word_generator(base_word_input: str) -> str:
    if not base_word_input or len(base_word_input) < 2: return "KelimatÃ¶rProMax"
    vowels_set = "aeiouÃ¼Ã¶Ä±AEIOUÃœÃ–I"; consonants_set = "bcÃ§dfgÄŸhjklmnprsÅŸtvyzBCÃ‡DFGÄHJKLMNPRSÅTVYZ"
    cleaned_base_word = "".join(filter(str.isalpha, base_word_input))
    if not cleaned_base_word: return "SÃ¶zcÃ¼kMimarUzmanÄ±"
    prefixes_list = ["bio", "krono", "psiko", "tera", "neo", "mega", "nano", "astro", "poli", "eko", "meta", "trans", "ultra", "omni", "xeno", "kripto", "holo"]
    suffixes_list = ["genez", "sfer", "nomi", "tek", "loji", "tronik", "morf", "vers", "dinamik", "matik", "kinezis", "skop", "grafi", "mant", "krom", "faz", "sentez"]
    
    if len(cleaned_base_word) > 3 and random.random() < 0.75:
        start_index = random.randint(0, max(0, len(cleaned_base_word) - 3))
        core_word_part = cleaned_base_word[start_index : start_index + random.randint(2,4)]
    else:
        core_length = random.randint(3, 5)
        core_chars_list = [random.choice(consonants_set if random.random() > 0.4 else vowels_set) for _ in range(core_length)]
        core_word_part = "".join(core_chars_list)
    
    new_generated_word = core_word_part
    if random.random() > 0.4: new_generated_word = random.choice(prefixes_list) + new_generated_word
    if random.random() > 0.4: new_generated_word += random.choice(suffixes_list)
    
    return new_generated_word.capitalize() if len(new_generated_word) > 1 else new_generated_word

def generate_prompt_influenced_image(prompt_text: str) -> Image.Image:
    width, height = 512, 512
    prompt_lower_case = prompt_text.lower()
    keyword_themes_map = {
        "gÃ¼neÅŸ": {"bg": [(255, 230, 150), (255, 160, 0)], "shapes": [{"type": "circle", "color": (255, 255, 0, 220), "pos": (random.uniform(0.2,0.35), random.uniform(0.2,0.35)), "size": random.uniform(0.18,0.25)}]},
        "ay": {"bg": [(10, 10, 50), (40, 40, 100)], "shapes": [{"type": "circle", "color": (240, 240, 240, 200), "pos": (random.uniform(0.65,0.8), random.uniform(0.15,0.3)), "size": random.uniform(0.12,0.18)}]},
        "gÃ¶kyÃ¼zÃ¼": {"bg": [(135, 206, 250), (70, 130, 180)], "shapes": []},
        "deniz": {"bg": [(0, 105, 148), (0, 0, 100)], "shapes": [{"type": "rectangle", "color": (60,120,180, 150), "pos": (0.5, 0.75), "size": (1.0, 0.5)}]},
        "orman": {"bg": [(34, 139, 34), (0, 100, 0)], "shapes": [{"type": "triangle", "color": (random.randint(0,30),random.randint(70,100),random.randint(0,30),200), "pos": (random.uniform(0.1,0.9), random.uniform(0.4,0.75)), "size": random.uniform(0.08,0.28)} for _ in range(random.randint(5,10))]},
        "aÄŸaÃ§": {"bg": [(180, 220, 180), (140, 190, 140)], "shapes": [ {"type": "rectangle", "color": (139, 69, 19, 255), "pos": (0.5, 0.75), "size": (0.08, 0.4)}, {"type": "ellipse", "color": (34, 139, 34, 200), "pos": (0.5, 0.45), "size_wh": (0.3, 0.25)} ]},
        "daÄŸ": {"bg": [(200,200,200), (100,100,100)], "shapes": [{"type": "triangle", "color": (random.randint(130,170),random.randint(130,170),random.randint(130,170),230), "pos": (0.5,0.6), "size":0.4, "points": [(random.uniform(0.05,0.35),0.85),(0.5,random.uniform(0.05,0.35)),(random.uniform(0.65,0.95),0.85)] } for _ in range(random.randint(1,3))]},
        "ÅŸehir": {"bg": [(100,100,120), (50,50,70)], "shapes": [{"type":"rectangle", "color":(random.randint(60,100),random.randint(60,100),random.randint(70,110),random.randint(180,220)), "pos":(random.uniform(0.1,0.9), random.uniform(0.4,0.85)), "size": (random.uniform(0.04,0.15), random.uniform(0.15,0.65))} for _ in range(random.randint(7,12))]}
    }
    bg_color1_tuple = (random.randint(30, 120), random.randint(30, 120), random.randint(30, 120))
    bg_color2_tuple = (random.randint(120, 220), random.randint(120, 220), random.randint(120, 220))
    shapes_to_draw_list = []
    num_themes_applied = 0

    for keyword_theme, theme_details in keyword_themes_map.items():
        if keyword_theme in prompt_lower_case:
            if num_themes_applied == 0:
                bg_color1_tuple, bg_color2_tuple = theme_details["bg"]
            shapes_to_draw_list.extend(theme_details["shapes"])
            num_themes_applied +=1

    image_canvas = Image.new('RGBA', (width, height), (0,0,0,0))
    draw_context = ImageDraw.Draw(image_canvas)

    for y_coordinate in range(height):
        blend_ratio = y_coordinate / height
        r_channel = int(bg_color1_tuple[0] * (1 - blend_ratio) + bg_color2_tuple[0] * blend_ratio)
        g_channel = int(bg_color1_tuple[1] * (1 - blend_ratio) + bg_color2_tuple[1] * blend_ratio)
        b_channel = int(bg_color1_tuple[2] * (1 - blend_ratio) + bg_color2_tuple[2] * blend_ratio)
        draw_context.line([(0, y_coordinate), (width, y_coordinate)], fill=(r_channel, g_channel, b_channel, 255))

    for shape_properties in shapes_to_draw_list:
        shape_type = shape_properties["type"]
        shape_color = shape_properties["color"]
        shape_pos_x_ratio, shape_pos_y_ratio = shape_properties["pos"]
        shape_center_x = int(shape_pos_x_ratio * width)
        shape_center_y = int(shape_pos_y_ratio * height)
        shape_outline_color = (0,0,0,50) if len(shape_color) == 4 and shape_color[3] < 250 else None

        if shape_type == "circle":
            shape_radius = int(shape_properties["size"] * min(width, height) / 2)
            draw_context.ellipse((shape_center_x - shape_radius, shape_center_y - shape_radius, shape_center_x + shape_radius, shape_center_y + shape_radius), fill=shape_color, outline=shape_outline_color)
        elif shape_type == "rectangle":
            shape_width_ratio, shape_height_ratio = shape_properties["size"]
            rect_width_pixels = int(shape_width_ratio * width)
            rect_height_pixels = int(shape_height_ratio * height)
            draw_context.rectangle((shape_center_x - rect_width_pixels // 2, shape_center_y - rect_height_pixels // 2, shape_center_x + rect_width_pixels // 2, shape_center_y + rect_height_pixels // 2), fill=shape_color, outline=shape_outline_color)
        elif shape_type == "triangle" and "points" in shape_properties:
            absolute_points_list = [(int(point[0]*width), int(point[1]*height)) for point in shape_properties["points"]]
            draw_context.polygon(absolute_points_list, fill=shape_color, outline=shape_outline_color)
        elif shape_type == "triangle":
            shape_base_size = int(shape_properties["size"] * min(width, height))
            point1 = (shape_center_x, shape_center_y - int(shape_base_size * 0.577))
            point2 = (shape_center_x - shape_base_size // 2, shape_center_y + int(shape_base_size * 0.288))
            point3 = (shape_center_x + shape_base_size // 2, shape_center_y + int(shape_base_size * 0.288))
            draw_context.polygon([point1, point2, point3], fill=shape_color, outline=shape_outline_color)
        elif shape_type == "ellipse":
            ellipse_size_wh_ratios = shape_properties["size_wh"]
            ellipse_width_pixels = int(ellipse_size_wh_ratios[0] * width)
            ellipse_height_pixels = int(ellipse_size_wh_ratios[1] * height)
            draw_context.ellipse((shape_center_x - ellipse_width_pixels // 2, shape_center_y - ellipse_height_pixels // 2, shape_center_x + ellipse_width_pixels // 2, shape_center_y + ellipse_height_pixels // 2), fill=shape_color, outline=shape_outline_color)

    if num_themes_applied == 0:
        for _ in range(random.randint(3, 6)):
            x1_coord = random.randint(0, width)
            y1_coord = random.randint(0, height)
            random_shape_fill_color = (random.randint(50, 250), random.randint(50, 250), random.randint(50, 250), random.randint(150, 220))
            
            # Bu if/else bloÄŸunun girintisi 'for' dÃ¶ngÃ¼sÃ¼ne gÃ¶re doÄŸru olmalÄ±
            if random.random() > 0.5:
                random_radius = random.randint(25, 85)
                draw_context.ellipse((x1_coord - random_radius, y1_coord - random_radius, x1_coord + random_radius, y1_coord + random_radius), fill=random_shape_fill_color)
            else:
                random_rect_w, random_rect_h = random.randint(35, 125), random.randint(35, 125)
                draw_context.rectangle((x1_coord - random_rect_w // 2, y1_coord - random_rect_h // 2, x1_coord + random_rect_w // 2, y1_coord + random_rect_h // 2), fill=random_shape_fill_color)

    try:
        calculated_font_size = max(16, min(30, int(width / (len(prompt_text) * 0.35 + 10))))
        font_object_to_use = None
        if os.path.exists(FONT_FILE):
            try:
                font_object_to_use = ImageFont.truetype(FONT_FILE, calculated_font_size)
            except IOError:
                st.toast(f"Font dosyasÄ± '{FONT_FILE}' yÃ¼klenemedi. VarsayÄ±lan font kullanÄ±lacak.", icon="âš ï¸")
        
        if not font_object_to_use:
            font_object_to_use = ImageFont.load_default()
            # VarsayÄ±lan font kullanÄ±ldÄ±ÄŸÄ±nda boyut farklÄ± olabileceÄŸi iÃ§in bir not dÃ¼ÅŸÃ¼lebilir
            # st.toast(f"VarsayÄ±lan font kullanÄ±lÄ±yor, metin boyutu istenen '{calculated_font_size}px' olmayabilir.", icon="â„¹ï¸")

        text_to_display_on_image = prompt_text[:70]
        if hasattr(draw_context, 'textbbox'):
            text_bounding_box = draw_context.textbbox((0,0), text_to_display_on_image, font=font_object_to_use, anchor="lt")
            text_render_width = text_bounding_box[2] - text_bounding_box[0]
            text_render_height = text_bounding_box[3] - text_bounding_box[1]
        else:
            text_render_width, text_render_height = draw_context.textsize(text_to_display_on_image, font=font_object_to_use)

        text_x_position = (width - text_render_width) / 2
        text_y_position = height * 0.93 - text_render_height
        draw_context.text((text_x_position + 1, text_y_position + 1), text_to_display_on_image, font=font_object_to_use, fill=(0,0,0,150))
        draw_context.text((text_x_position, text_y_position), text_to_display_on_image, font=font_object_to_use, fill=(255,255,255,230))
    except Exception as e_font_drawing:
        st.toast(f"GÃ¶rsel Ã¼zerine metin yazdÄ±rÄ±lÄ±rken bir hata oluÅŸtu: {e_font_drawing}", icon="ğŸ“")

    return image_canvas.convert("RGB")

# --- Session State BaÅŸlatma ---
DEFAULT_SESSION_STATE_VALUES = {
    'chat_history': [], 'app_mode': "YazÄ±lÄ± Sohbet", 'user_name': None,
    'user_avatar_bytes': None, 'show_main_app': False, 'greeting_message_shown': False,
    'tts_enabled': True, 'theme': "Light",
    'gemini_stream_enabled': True, 'gemini_temperature': 0.7, 'gemini_top_p': 0.95,
    'gemini_top_k': 40, 'gemini_max_tokens': 4096, 'gemini_model_name': 'gemini-1.5-flash-latest',
    'message_id_counter': 0, 'last_ai_response_for_feedback': None,
    'last_user_prompt_for_feedback': None, 'current_message_id_for_feedback': None,
    'feedback_comment_input': "", 'show_feedback_comment_form': False,
    'session_id': str(uuid.uuid4())
}
for key_ss, default_val_ss in DEFAULT_SESSION_STATE_VALUES.items():
    if key_ss not in st.session_state: st.session_state[key_ss] = default_val_ss

if 'models_initialized' not in st.session_state:
    gemini_model = initialize_gemini_model()
    supabase = init_supabase_client_cached()
    tts_engine = init_tts_engine_cached()
    st.session_state.models_initialized = True
else:
    gemini_model = globals().get('gemini_model')
    supabase = globals().get('supabase')
    tts_engine = globals().get('tts_engine')

gemini_init_error = globals().get('gemini_init_error_global')
supabase_error = globals().get('supabase_error_global')
tts_init_error = globals().get('tts_init_error_global')

if not st.session_state.chat_history:
    st.session_state.chat_history = load_chat_history_cached()
if st.session_state.user_name and not st.session_state.show_main_app:
    st.session_state.show_main_app = True

# --- ARAYÃœZ BÃ–LÃœMLERÄ° Ä°Ã‡Ä°N FONKSÄ°YONLAR ---
def display_sidebar_content():
    with st.sidebar:
        st.markdown(f"### HoÅŸ Geldin, {st.session_state.user_name}!")
        if st.session_state.user_avatar_bytes:
            st.image(st.session_state.user_avatar_bytes, width=100, use_column_width='auto', caption="AvatarÄ±nÄ±z")
        else:
            st.caption("ğŸ–¼ï¸ _HenÃ¼z bir avatar yÃ¼klemediniz._")
        st.markdown("---")
        st.subheader("âš™ï¸ Ayarlar ve KiÅŸiselleÅŸtirme")

        with st.expander("ğŸ‘¤ Profil AyarlarÄ±", expanded=False):
            new_user_name = st.text_input("AdÄ±nÄ±zÄ± DeÄŸiÅŸtirin:", value=st.session_state.user_name, key="change_name_sidebar_input")
            if new_user_name != st.session_state.user_name and new_user_name.strip():
                st.session_state.user_name = new_user_name.strip()
                st.toast("AdÄ±nÄ±z baÅŸarÄ±yla gÃ¼ncellendi!", icon="âœï¸"); st.rerun()

            uploaded_avatar_file = st.file_uploader("Yeni Avatar YÃ¼kle (PNG, JPG - Maks 2MB):", type=["png", "jpg", "jpeg"], key="avatar_uploader_sidebar_file")
            if uploaded_avatar_file:
                if uploaded_avatar_file.size > 2 * 1024 * 1024:
                    st.error("Dosya boyutu 2MB'den bÃ¼yÃ¼k olamaz! LÃ¼tfen daha kÃ¼Ã§Ã¼k bir dosya seÃ§in.", icon=" oversized_file:")
                else:
                    st.session_state.user_avatar_bytes = uploaded_avatar_file.getvalue()
                    st.toast("AvatarÄ±nÄ±z baÅŸarÄ±yla gÃ¼ncellendi!", icon="ğŸ–¼ï¸"); st.rerun()
            
            if st.session_state.user_avatar_bytes and st.button("ğŸ—‘ï¸ Mevcut AvatarÄ± KaldÄ±r", use_container_width=True, key="remove_avatar_sidebar_button"):
                st.session_state.user_avatar_bytes = None
                st.toast("AvatarÄ±nÄ±z kaldÄ±rÄ±ldÄ±.", icon="ğŸ—‘ï¸"); st.rerun()
            st.caption("AvatarÄ±nÄ±z sadece bu tarayÄ±cÄ± oturumunda saklanÄ±r.")

        current_tts_engine = globals().get('tts_engine')
        st.session_state.tts_enabled = st.toggle("Metin Okuma (TTS) Aktif", value=st.session_state.tts_enabled, disabled=not current_tts_engine, help="AI yanÄ±tlarÄ±nÄ±n sesli okunmasÄ±nÄ± aÃ§ar veya kapatÄ±r.")
        st.session_state.gemini_stream_enabled = st.toggle("Gemini YanÄ±t AkÄ±ÅŸÄ±nÄ± EtkinleÅŸtir", value=st.session_state.gemini_stream_enabled, help="YanÄ±tlarÄ±n kelime kelime gelmesini saÄŸlar (daha hÄ±zlÄ± ilk tepki).")

        with st.expander("ğŸ¤– Gemini GeliÅŸmiÅŸ YapÄ±landÄ±rma", expanded=False):
            st.session_state.gemini_model_name = st.selectbox(
                "KullanÄ±lacak Gemini Modeli:",
                ['gemini-1.5-flash-latest', 'gemini-1.5-pro-latest'],
                index=0 if st.session_state.gemini_model_name == 'gemini-1.5-flash-latest' else 1,
                key="gemini_model_selector_sidebar",
                help="FarklÄ± modellerin yetenekleri ve maliyetleri deÄŸiÅŸebilir."
            )
            st.session_state.gemini_temperature = st.slider("SÄ±caklÄ±k (YaratÄ±cÄ±lÄ±k Seviyesi):", 0.0, 1.0, st.session_state.gemini_temperature, 0.05, key="gemini_temp_slider_sidebar", help="DÃ¼ÅŸÃ¼k deÄŸerler daha kesin, yÃ¼ksek deÄŸerler daha yaratÄ±cÄ± yanÄ±tlar Ã¼retir.")
            st.session_state.gemini_top_p = st.slider("Top P (Odaklanma DÃ¼zeyi):", 0.0, 1.0, st.session_state.gemini_top_p, 0.05, key="gemini_top_p_slider_sidebar", help="YanÄ±tlarÄ±n ne kadar odaklÄ± olacaÄŸÄ±nÄ± belirler. Genellikle 1.0 veya 0.95 kullanÄ±lÄ±r.")
            st.session_state.gemini_top_k = st.slider("Top K (Ã‡eÅŸitlilik Filtresi):", 1, 100, st.session_state.gemini_top_k, 1, key="gemini_top_k_slider_sidebar", help="YanÄ±t oluÅŸturulurken en olasÄ± K token arasÄ±ndan seÃ§im yapÄ±lmasÄ±nÄ± saÄŸlar.")
            st.session_state.gemini_max_tokens = st.slider("Maksimum Ã‡Ä±ktÄ± Token SayÄ±sÄ±:", 256, 8192, st.session_state.gemini_max_tokens, 128, key="gemini_max_tokens_slider_sidebar", help="Modelin Ã¼reteceÄŸi yanÄ±tÄ±n maksimum uzunluÄŸunu sÄ±nÄ±rlar.")
            
            if st.button("âš™ï¸ Gemini AyarlarÄ±nÄ± Uygula ve Modeli Yeniden BaÅŸlat", key="reload_gemini_settings_sidebar_btn", use_container_width=True, type="primary"):
                global gemini_model
                gemini_model = initialize_gemini_model()
                if gemini_model: st.toast("Gemini ayarlarÄ± baÅŸarÄ±yla gÃ¼ncellendi ve model yeniden yÃ¼klendi!", icon="âœ¨")
                else: st.error("Gemini modeli gÃ¼ncellenirken bir hata oluÅŸtu. LÃ¼tfen API anahtarÄ±nÄ±zÄ± ve yapÄ±landÄ±rma ayarlarÄ±nÄ±zÄ± kontrol edin.")

        st.divider()
        if st.button("ğŸ§¹ Sohbet GeÃ§miÅŸini Temizle", use_container_width=True, type="secondary", key="clear_history_sidebar_main_btn"):
            if st.session_state.chat_history:
                st.session_state.chat_history = []
                save_chat_history([])
                st.toast("Sohbet geÃ§miÅŸi baÅŸarÄ±yla temizlendi!", icon="ğŸ§¹"); st.rerun()
            else:
                st.toast("Sohbet geÃ§miÅŸi zaten boÅŸ.", icon="â„¹ï¸")

        with st.expander("â„¹ï¸ Uygulama HakkÄ±nda", expanded=True): # BaÅŸlangÄ±Ã§ta aÃ§Ä±k olsun
            st.markdown(f"""
            **{APP_NAME} v{APP_VERSION}**
            Yapay zeka destekli kiÅŸisel sohbet asistanÄ±nÄ±z.
            GeliÅŸtirici: **Hanogt** ([GitHub](https://github.com/Hanogt))

            Bu uygulama Streamlit, Google Gemini API ve Ã§eÅŸitli Python aÃ§Ä±k kaynak kÃ¼tÃ¼phaneleri kullanÄ±larak geliÅŸtirilmiÅŸtir.
            KullanÄ±cÄ± etkileÅŸimleri ve geri bildirimler, isteÄŸe baÄŸlÄ± olarak Supabase Ã¼zerinde gÃ¼venli bir ÅŸekilde saklanabilir.
            TÃ¼m haklarÄ± saklÄ±dÄ±r Â© 2024-{CURRENT_YEAR}
            """)
        st.caption(f"{APP_NAME} v{APP_VERSION} - Oturum ID: {st.session_state.session_id[:8]}...")

def display_chat_message_with_feedback(sender_name: str, message_text_content: str, message_unique_index: int, is_user_message: bool):
    avatar_display_icon = "ğŸ§‘"
    if is_user_message:
        if st.session_state.user_avatar_bytes:
            try: avatar_display_icon = Image.open(BytesIO(st.session_state.user_avatar_bytes))
            except Exception: pass
    else:
        if "Gemini" in sender_name: avatar_display_icon = "âœ¨"
        elif "Web" in sender_name: avatar_display_icon = "ğŸŒ"
        elif "Bilgi TabanÄ±" in sender_name or "Fonksiyonel" in sender_name: avatar_display_icon = "ğŸ“š"
        else: avatar_display_icon = "ğŸ¤–"

    with st.chat_message("user" if is_user_message else "assistant", avatar=avatar_display_icon):
        if "```" in message_text_content:
            code_block_parts = message_text_content.split("```")
            for i, part_text in enumerate(code_block_parts):
                if i % 2 == 1:
                    language_match = re.match(r"(\w+)\n", part_text)
                    code_language = language_match.group(1) if language_match else None
                    actual_code_content = part_text[len(code_language)+1:] if code_language and part_text.startswith(code_language+"\n") else part_text
                    
                    st.code(actual_code_content, language=code_language)
                    if st.button("ğŸ“‹ Kopyala", key=f"copy_code_btn_{message_unique_index}_{i}", help="Bu kod bloÄŸunu panoya kopyala"):
                        st.write_to_clipboard(actual_code_content)
                        st.toast("Kod baÅŸarÄ±yla panoya kopyalandÄ±!", icon="âœ…")
                else:
                    st.markdown(part_text, unsafe_allow_html=True)
        else:
            st.markdown(message_text_content, unsafe_allow_html=True)

        if not is_user_message:
            ai_response_source_name = sender_name.split('(')[-1].replace(')','').strip() if '(' in sender_name else sender_name.replace(f'{APP_NAME} ','')
            action_cols = st.columns([0.7, 0.15, 0.15])
            with action_cols[0]:
                st.caption(f"Kaynak: {ai_response_source_name}")
            with action_cols[1]:
                current_tts_engine = globals().get('tts_engine')
                if st.session_state.tts_enabled and current_tts_engine and message_text_content:
                    if st.button("ğŸ”Š", key=f"speak_msg_btn_chat_{message_unique_index}", help="Bu mesajÄ± sesli oku", use_container_width=True):
                        speak(message_text_content)
            with action_cols[2]:
                if st.button("âœï¸", key=f"toggle_feedback_btn_chat_{message_unique_index}", help="Bu yanÄ±t hakkÄ±nda geri bildirimde bulunun", use_container_width=True):
                    st.session_state.current_message_id_for_feedback = f"chat_{message_unique_index}"
                    st.session_state.last_user_prompt_for_feedback = st.session_state.chat_history[message_unique_index-1][1] if message_unique_index > 0 else "N/A (Prompt bulunamadÄ±)"
                    st.session_state.last_ai_response_for_feedback = message_text_content
                    st.session_state.show_feedback_comment_form = not st.session_state.get('show_feedback_comment_form', False)
                    if not st.session_state.show_feedback_comment_form:
                        st.session_state.feedback_comment_input = ""
                    st.rerun()

def display_feedback_form_if_active():
    if st.session_state.get('show_feedback_comment_form') and st.session_state.current_message_id_for_feedback:
        st.markdown("---")
        with st.form(key=f"feedback_submission_form_{st.session_state.current_message_id_for_feedback}"):
            st.markdown(f"#### Geri Bildiriminiz")
            st.caption(f"**Ä°stem:** `{st.session_state.last_user_prompt_for_feedback[:70]}...`")
            st.caption(f"**YanÄ±t:** `{st.session_state.last_ai_response_for_feedback[:70]}...`")

            feedback_rating_type = st.radio(
                "Bu yanÄ±tÄ± nasÄ±l deÄŸerlendirirsiniz?",
                ["ğŸ‘ BeÄŸendim", "ğŸ‘ BeÄŸenmedim"],
                horizontal=True, key="feedback_type_radio_form",
                index=0 if st.session_state.get('last_feedback_type', 'positive') == 'positive' else 1
            )
            user_feedback_comment = st.text_area(
                "Yorumunuz (isteÄŸe baÄŸlÄ±, Ã¶zellikle beÄŸenmediyseniz nedenini belirtmeniz Ã§ok yardÄ±mcÄ± olur):",
                value=st.session_state.get('feedback_comment_input', ""),
                key="feedback_comment_textarea_form", height=100
            )
            st.session_state.feedback_comment_input = user_feedback_comment

            submitted_feedback_button = st.form_submit_button("âœ… Geri Bildirimi GÃ¶nder ve Formu Kapat", type="primary")

            if submitted_feedback_button:
                parsed_feedback_category = "positive" if feedback_rating_type == "ğŸ‘ BeÄŸendim" else "negative"
                st.session_state.last_feedback_type = parsed_feedback_category

                if log_feedback(
                    st.session_state.current_message_id_for_feedback,
                    st.session_state.last_user_prompt_for_feedback,
                    st.session_state.last_ai_response_for_feedback,
                    parsed_feedback_category,
                    user_feedback_comment
                ):
                    st.session_state.show_feedback_comment_form = False
                    st.session_state.feedback_comment_input = ""
                    st.session_state.current_message_id_for_feedback = None
                    st.rerun()
        st.markdown("---")

def display_chat_interface_main():
    chat_display_container = st.container()
    with chat_display_container:
        if not st.session_state.chat_history:
            st.info(f"Merhaba {st.session_state.user_name}! Size nasÄ±l yardÄ±mcÄ± olabilirim? LÃ¼tfen aÅŸaÄŸÄ±dan mesajÄ±nÄ±zÄ± yazÄ±n.", icon="ğŸ‘‹")
        
        for i, (sender_id_name, message_content_text) in enumerate(st.session_state.chat_history):
            display_chat_message_with_feedback(sender_id_name, message_content_text, i, sender_id_name.startswith("Sen"))

    display_feedback_form_if_active()

    if user_new_prompt := st.chat_input(f"{st.session_state.user_name} olarak mesajÄ±nÄ±zÄ± yazÄ±n...", key="main_chat_input_field_bottom"):
        current_message_unique_id = f"msg_{st.session_state.message_id_counter}_{int(time.time())}"
        st.session_state.message_id_counter += 1
        st.session_state.chat_history.append(("Sen", user_new_prompt))

        raw_history_for_gemini = st.session_state.chat_history[-21:-1]
        gemini_formatted_chat_history = [{'role': ("user" if sender.startswith("Sen") else "model"), 'parts': [message]} for sender, message in raw_history_for_gemini]

        with st.chat_message("assistant", avatar="â³"):
            thinking_placeholder = st.empty()
            thinking_placeholder.markdown("ğŸ§  _DÃ¼ÅŸÃ¼nÃ¼yorum... LÃ¼tfen bekleyin..._")
            time.sleep(0.05) # Placeholder'Ä±n gÃ¶rÃ¼nmesi iÃ§in Ã§ok kÄ±sa bekleme

        ai_response_data, ai_sender_identity = get_hanogt_response_orchestrator(
            user_new_prompt,
            gemini_formatted_chat_history,
            current_message_unique_id,
            use_stream_output=st.session_state.gemini_stream_enabled
        )

        if st.session_state.gemini_stream_enabled and ai_sender_identity == f"{APP_NAME} (Gemini Stream)":
            streamed_full_response_text = ""
            try:
                for chunk_index, stream_chunk in enumerate(ai_response_data):
                    if stream_chunk.parts:
                        text_from_chunk = "".join(part.text for part in stream_chunk.parts if hasattr(part, 'text'))
                        streamed_full_response_text += text_from_chunk
                        thinking_placeholder.markdown(streamed_full_response_text + "â–Œ")
                        if chunk_index % 5 == 0: time.sleep(0.005) 
                thinking_placeholder.markdown(streamed_full_response_text)
                log_interaction(user_new_prompt, streamed_full_response_text, ai_sender_identity, current_message_unique_id)
                st.session_state.chat_history.append((ai_sender_identity, streamed_full_response_text))
            except Exception as e_stream_processing:
                error_text_stream = f"Stream yanÄ±tÄ± iÅŸlenirken bir hata oluÅŸtu: {e_stream_processing}"
                thinking_placeholder.error(error_text_stream)
                st.session_state.chat_history.append((f"{APP_NAME} (Stream HatasÄ±)", error_text_stream))
        else:
            thinking_placeholder.empty()
            st.session_state.chat_history.append((ai_sender_identity, str(ai_response_data)))

        save_chat_history(st.session_state.chat_history)
        
        if st.session_state.tts_enabled and globals().get('tts_engine') and \
           isinstance(ai_response_data, str) and not \
           (st.session_state.gemini_stream_enabled and ai_sender_identity == f"{APP_NAME} (Gemini Stream)"):
            speak(ai_response_data)
        
        st.rerun()

# --- UYGULAMA ANA AKIÅI (MAIN FLOW) ---
st.markdown(f"<h1 style='text-align: center; color: #0078D4;'>ğŸš€ {APP_NAME} {APP_VERSION} ğŸš€</h1>", unsafe_allow_html=True)
st.markdown(f"<p style='text-align: center; font-style: italic; color: #555;'>Yapay zeka destekli kiÅŸisel sohbet asistanÄ±nÄ±z!</p>", unsafe_allow_html=True)

if gemini_init_error: st.error(gemini_init_error, icon="ğŸ›‘")
if supabase_error: st.error(supabase_error, icon="ğŸ§±")
if tts_init_error and st.session_state.tts_enabled:
    st.toast(tts_init_error, icon="ğŸ”‡")

if not st.session_state.show_main_app:
    st.subheader("ğŸ‘‹ Merhaba! BaÅŸlamadan Ã–nce Sizi TanÄ±yabilir Miyim?")
    login_form_cols = st.columns([0.15, 0.7, 0.15])
    with login_form_cols[1]:
        with st.form("user_details_login_form"):
            user_name_input = st.text_input(
                "Size nasÄ±l hitap etmeliyim?",
                placeholder="Ä°sminiz veya takma adÄ±nÄ±z...",
                value=st.session_state.get('user_name_temp', ''),
                key="user_name_login_input_field"
            )
            login_submitted_button = st.form_submit_button("âœ¨ BaÅŸlayalÄ±m!", use_container_width=True, type="primary")
            
            if login_submitted_button:
                if user_name_input and user_name_input.strip():
                    st.session_state.user_name = user_name_input.strip()
                    st.session_state.show_main_app = True
                    st.session_state.greeting_message_shown = False
                    st.rerun()
                else:
                    st.error("LÃ¼tfen geÃ§erli bir isim veya takma ad girin.")
else:
    if not st.session_state.greeting_message_shown and st.session_state.user_name:
        greeting_message = random.choice([
            f"Tekrar hoÅŸ geldiniz, SayÄ±n {st.session_state.user_name}! BugÃ¼n size nasÄ±l yardÄ±mcÄ± olabilirim?",
            f"Merhaba {st.session_state.user_name}! Sizin iÃ§in hazÄ±rÄ±m, ne merak ediyorsunuz?",
            f"Harika bir gÃ¼n geÃ§irmeniz dileÄŸiyle, {st.session_state.user_name}! Ne yapmak istersiniz?"
        ])
        st.success(greeting_message, icon="ğŸ‰"); st.session_state.greeting_message_shown = True
        st.balloons()

    display_sidebar_content()

    app_mode_options_map = {
        "YazÄ±lÄ± Sohbet": "ğŸ’¬", "Sesli Sohbet (Dosya YÃ¼kle)": "ğŸ¤",
        "YaratÄ±cÄ± StÃ¼dyo": "ğŸ¨", "GÃ¶rsel OluÅŸturucu": "ğŸ–¼ï¸"
    }
    selected_app_mode_key = st.radio(
        "Uygulama Modunu SeÃ§in:",
        options=list(app_mode_options_map.keys()),
        index=list(app_mode_options_map.keys()).index(st.session_state.app_mode),
        format_func=lambda mode_key: f"{app_mode_options_map[mode_key]} {mode_key}",
        horizontal=True, label_visibility="collapsed", key="app_mode_selector_radio"
    )
    if selected_app_mode_key != st.session_state.app_mode:
        st.session_state.app_mode = selected_app_mode_key; st.rerun()
    current_app_mode = st.session_state.app_mode
    st.markdown("<hr style='margin-top: 0.5rem; margin-bottom: 0.5rem;'>", unsafe_allow_html=True)

    if current_app_mode == "YazÄ±lÄ± Sohbet":
        display_chat_interface_main()

    elif current_app_mode == "Sesli Sohbet (Dosya YÃ¼kle)":
        st.info("LÃ¼tfen yanÄ±tlamamÄ± istediÄŸiniz konuÅŸmayÄ± iÃ§eren bir ses dosyasÄ± (WAV, MP3, OGG, FLAC, M4A formatlarÄ±nda) yÃ¼kleyin.", icon="ğŸ“¢")
        uploaded_audio_file = st.file_uploader(
            "Ses DosyasÄ± SeÃ§in:", type=['wav', 'mp3', 'ogg', 'flac', 'm4a'],
            label_visibility="collapsed", key="audio_file_uploader_page_main"
        )
        if uploaded_audio_file:
            st.audio(uploaded_audio_file, format=uploaded_audio_file.type)
            user_prompt_from_audio = None; audio_file_name = uploaded_audio_file.name
            temp_audio_file_path = f"temp_audio_{st.session_state.session_id}_{re.sub(r'[^a-zA-Z0-9_.-]', '', audio_file_name)[:20]}.wav"

            with st.spinner(f"ğŸ”Š '{audio_file_name}' ses dosyasÄ± iÅŸleniyor... LÃ¼tfen bekleyin."):
                speech_recognizer = sr.Recognizer();
                try:
                    with open(temp_audio_file_path, "wb") as temp_f: temp_f.write(uploaded_audio_file.getbuffer())
                    with sr.AudioFile(temp_audio_file_path) as audio_source:
                        audio_data_recorded = speech_recognizer.record(audio_source)
                    user_prompt_from_audio = speech_recognizer.recognize_google(audio_data_recorded, language="tr-TR")
                    st.success(f"**ğŸ™ï¸ AlgÄ±lanan Metin:**\n\n> {user_prompt_from_audio}")
                except sr.UnknownValueError:
                    st.error("ğŸ”‡ ÃœzgÃ¼nÃ¼m, ses anlaÅŸÄ±lamadÄ±. LÃ¼tfen daha net bir ses dosyasÄ± deneyin veya ses kalitesini kontrol edin.")
                except sr.RequestError as e_sr_request:
                    st.error(f"ğŸ¤– Ses tanÄ±ma servisine ulaÅŸÄ±lamadÄ±: {e_sr_request}. LÃ¼tfen internet baÄŸlantÄ±nÄ±zÄ± kontrol edin.")
                except Exception as e_audio_processing:
                    st.error(f"Ses dosyasÄ± iÅŸlenirken beklenmedik bir hata oluÅŸtu: {e_audio_processing}")
                finally:
                    if os.path.exists(temp_audio_file_path): os.remove(temp_audio_file_path)

            if user_prompt_from_audio:
                current_message_id_audio_mode = f"audio_msg_{st.session_state.message_id_counter}_{int(time.time())}"
                st.session_state.message_id_counter += 1
                st.session_state.chat_history.append(("Sen (Ses DosyasÄ±ndan)", user_prompt_from_audio))
                raw_history_for_gemini_audio = st.session_state.chat_history[-21:-1]
                gemini_formatted_history_audio = [{'role': ("user" if sender.startswith("Sen") else "model"), 'parts': [message]} for sender, message in raw_history_for_gemini_audio]
                
                with st.spinner("ğŸ¤– Yapay zeka yanÄ±tÄ±nÄ±zÄ± hazÄ±rlÄ±yor..."):
                    ai_response_audio, ai_sender_audio_mode = get_hanogt_response_orchestrator(user_prompt_from_audio, gemini_formatted_history_audio, current_message_id_audio_mode, use_stream_output=False)
                
                st.markdown(f"#### {ai_sender_audio_mode} YanÄ±tÄ±:")
                st.markdown(ai_response_audio)
                
                current_tts_engine_audio = globals().get('tts_engine')
                if st.session_state.tts_enabled and current_tts_engine_audio and ai_response_audio:
                    if st.button("ğŸ”Š AI YanÄ±tÄ±nÄ± Seslendir", key="speak_audio_response_button_page"):
                        speak(str(ai_response_audio))
                
                st.session_state.chat_history.append((ai_sender_audio_mode, str(ai_response_audio)))
                save_chat_history(st.session_state.chat_history)
                st.success("âœ… YanÄ±t baÅŸarÄ±yla oluÅŸturuldu ve genel sohbet geÃ§miÅŸine eklendi!")

    elif current_app_mode == "YaratÄ±cÄ± StÃ¼dyo":
        st.markdown("Bir fikir, bir kelime veya bir cÃ¼mle yazÄ±n. Hanogt AI size ilham verici ve yaratÄ±cÄ± bir yanÄ±t oluÅŸtursun!", icon="ğŸ’¡")
        user_creative_prompt_text = st.text_area(
            "YaratÄ±cÄ±lÄ±k Tohumunuzu Buraya Ekleyin:",
            key="creative_input_studio_main_page",
            placeholder="Ã–rneÄŸin: 'Ay Ä±ÅŸÄ±ÄŸÄ±nda dans eden bir tilkinin rÃ¼yasÄ± hakkÄ±nda kÄ±sa bir ÅŸiirsel metin'",
            height=120
        )
        creative_options_cols = st.columns(2)
        with creative_options_cols[0]:
            response_length_preference = st.selectbox(
                "Ä°stenen YanÄ±t UzunluÄŸu:",
                ["kÄ±sa", "orta", "uzun"], index=1,
                key="creative_length_preference_selector_page",
                help="Yapay zekanÄ±n Ã¼reteceÄŸi metnin yaklaÅŸÄ±k uzunluÄŸunu belirler."
            )
        with creative_options_cols[1]:
            response_style_preference = st.selectbox(
                "Ä°stenen YaratÄ±cÄ±lÄ±k Stili:",
                ["genel", "ÅŸiirsel", "hikaye"], index=0,
                key="creative_style_preference_selector_page",
                help="Yapay zekanÄ±n kullanacaÄŸÄ± yazÄ±m Ã¼slubunu seÃ§in."
            )

        if st.button("âœ¨ Ä°lham Veren Fikri Ãœret!", key="generate_creative_response_button_page", type="primary", use_container_width=True):
            if user_creative_prompt_text and user_creative_prompt_text.strip():
                final_creative_response_text = None; ai_sender_creative_mode = f"{APP_NAME} (YaratÄ±cÄ±)"
                current_message_id_creative_mode = f"creative_msg_{st.session_state.message_id_counter}_{int(time.time())}"
                st.session_state.message_id_counter += 1

                current_gemini_model_creative = globals().get('gemini_model')
                if current_gemini_model_creative:
                    with st.spinner("âœ¨ Gemini ilham perileriyle fÄ±sÄ±ldaÅŸÄ±yor ve sizin iÃ§in Ã¶zel bir metin hazÄ±rlÄ±yor..."):
                        gemini_creative_system_prompt_text = (
                            f"Sen Ã§ok yaratÄ±cÄ±, hayal gÃ¼cÃ¼ geniÅŸ ve edebi yÃ¶nÃ¼ kuvvetli bir asistansÄ±n. "
                            f"Sana verilen ÅŸu isteme: '{user_creative_prompt_text}' dayanarak, "
                            f"'{response_style_preference}' stilinde ve yaklaÅŸÄ±k '{response_length_preference}' uzunlukta Ã¶zgÃ¼n, ilginÃ§ ve sanatsal bir metin oluÅŸtur. "
                            "SÄ±radanlÄ±ktan kaÃ§Ä±n, okuyucuyu etkileyecek ve dÃ¼ÅŸÃ¼ndÃ¼recek bir dil kullan. EÄŸer uygunsa, metaforlar ve benzetmeler de kullanabilirsin."
                        )
                        gemini_creative_response = get_gemini_response_cached(gemini_creative_system_prompt_text, [], stream_output=False)
                        
                        if gemini_creative_response and not (isinstance(gemini_creative_response, str) and gemini_creative_response.startswith(GEMINI_ERROR_PREFIX)):
                            final_creative_response_text = str(gemini_creative_response)
                            ai_sender_creative_mode = f"{APP_NAME} (Gemini YaratÄ±cÄ±)"
                        else:
                            error_msg_creative = gemini_creative_response if isinstance(gemini_creative_response, str) else "Bilinmeyen bir sorun oluÅŸtu."
                            st.warning(f"Gemini yaratÄ±cÄ± yanÄ±tÄ± alÄ±namadÄ±. Yerel modÃ¼l kullanÄ±lacak. (Detay: {error_msg_creative.replace(GEMINI_ERROR_PREFIX, '').strip()})", icon="âš ï¸")
                
                if not final_creative_response_text:
                    with st.spinner("âœ¨ Kendi fikirlerimi demliyorum ve hayal gÃ¼cÃ¼mÃ¼n sÄ±nÄ±rlarÄ±nÄ± zorluyorum..."):
                        time.sleep(0.2)
                        local_creative_generated_text = creative_response_generator(user_creative_prompt_text, length_preference=response_length_preference, style_preference=response_style_preference)
                        newly_generated_word = advanced_word_generator(user_creative_prompt_text.split()[0] if user_creative_prompt_text else "kelime")
                        final_creative_response_text = f"{local_creative_generated_text}\n\n---\nğŸ”® **KelimatÃ¶rden TÃ¼retilen Ã–zel SÃ¶zcÃ¼k:** {newly_generated_word}"
                        ai_sender_creative_mode = f"{APP_NAME} (Yerel YaratÄ±cÄ±)"
                
                st.markdown(f"#### {ai_sender_creative_mode} Ä°lhamÄ±:")
                st.markdown(final_creative_response_text)
                
                current_tts_engine_creative = globals().get('tts_engine')
                if st.session_state.tts_enabled and current_tts_engine_creative and final_creative_response_text:
                    if st.button("ğŸ”Š Bu Ä°lham Veren Metni Dinle", key="speak_creative_response_button_page"):
                        text_to_speak_creative = final_creative_response_text.split("ğŸ”® **KelimatÃ¶rden TÃ¼retilen Ã–zel SÃ¶zcÃ¼k:**")[0].strip()
                        speak(text_to_speak_creative)
                
                log_interaction(user_creative_prompt_text, final_creative_response_text, ai_sender_creative_mode, current_message_id_creative_mode)
                st.success("âœ¨ YaratÄ±cÄ± yanÄ±tÄ±nÄ±z baÅŸarÄ±yla oluÅŸturuldu!")
            else:
                st.error("LÃ¼tfen yaratÄ±cÄ±lÄ±ÄŸÄ±nÄ±zÄ± ateÅŸleyecek bir fikir, kelime veya cÃ¼mle yazÄ±n!", icon="âœï¸")

    elif current_app_mode == "GÃ¶rsel OluÅŸturucu":
        st.markdown("Hayalinizdeki gÃ¶rseli tarif edin, Hanogt AI anahtar kelimelere gÃ¶re sizin iÃ§in (sembolik olarak) Ã§izecektir!", icon="ğŸ¨")
        st.info("â„¹ï¸ **Not:** Bu mod, girdiÄŸiniz metindeki anahtar kelimelere (Ã¶rneÄŸin: gÃ¼neÅŸ, deniz, aÄŸaÃ§, ay, gÃ¶kyÃ¼zÃ¼, orman, daÄŸ, ÅŸehir vb.) gÃ¶re basit, kural tabanlÄ± ve sembolik Ã§izimler yapar. LÃ¼tfen fotogerÃ§ekÃ§i veya karmaÅŸÄ±k sanat eserleri beklemeyin; bu daha Ã§ok prompt'unuzun eÄŸlenceli bir yorumlayÄ±cÄ±sÄ±dÄ±r.", icon="ğŸ’¡")
        
        user_image_prompt_text = st.text_input(
            "Ne tÃ¼r bir gÃ¶rsel hayal ediyorsunuz? (Anahtar kelimelerle tarif edin)",
            key="image_prompt_input_generator_page",
            placeholder="Ã–rnek: 'Gece vakti karlÄ± daÄŸlarÄ±n Ã¼zerinde parlayan bir dolunay ve birkaÃ§ Ã§am aÄŸacÄ±'"
        )
        
        if st.button("ğŸ–¼ï¸ Hayalimdeki GÃ¶rseli OluÅŸtur!", key="generate_rule_based_image_button_page", type="primary", use_container_width=True):
            if user_image_prompt_text and user_image_prompt_text.strip():
                with st.spinner("ğŸ–Œï¸ FÄ±rÃ§alarÄ±m ve renklerim hazÄ±rlanÄ±yor... Hayaliniz tuvale aktarÄ±lÄ±yor..."):
                    time.sleep(0.3)
                    generated_image_object = generate_prompt_influenced_image(user_image_prompt_text)
                
                st.image(generated_image_object, caption=f"{APP_NAME}'Ä±n '{user_image_prompt_text[:60]}' yorumu (Kural TabanlÄ± Ã‡izim)", use_container_width=True)
                
                try:
                    image_buffer = BytesIO()
                    generated_image_object.save(image_buffer, format="PNG")
                    image_bytes_for_download = image_buffer.getvalue()
                    
                    cleaned_prompt_for_filename = re.sub(r'[^\w\s-]', '', user_image_prompt_text.lower())
                    cleaned_prompt_for_filename = re.sub(r'\s+', '_', cleaned_prompt_for_filename).strip('_')[:35]
                    downloadable_file_name = f"hanogt_ai_cizim_{cleaned_prompt_for_filename or 'gorsel'}_{int(time.time())}.png"
                    
                    st.download_button(
                        label="ğŸ–¼ï¸ OluÅŸturulan GÃ¶rseli Ä°ndir (PNG)",
                        data=image_bytes_for_download,
                        file_name=downloadable_file_name,
                        mime="image/png",
                        use_container_width=True
                    )
                except Exception as e_image_download:
                    st.error(f"GÃ¶rsel indirilirken bir hata oluÅŸtu: {e_image_download}", icon="âš ï¸")
            else:
                st.error("LÃ¼tfen ne tÃ¼r bir gÃ¶rsel Ã§izmemi istediÄŸinizi aÃ§Ä±klayan bir metin girin!", icon="âœï¸")

    # --- Alt Bilgi (Footer) ---
    st.markdown("<hr style='margin-top: 1rem; margin-bottom: 0.5rem;'>", unsafe_allow_html=True)
    st.markdown(
        f"""
        <p style='text-align: center; font-size: 0.8rem; color: #777;'>
            {APP_NAME} v{APP_VERSION} &nbsp;&nbsp;|&nbsp;&nbsp; 
            KullanÄ±cÄ±: {st.session_state.get('user_name', 'Misafir')} &nbsp;&nbsp;|&nbsp;&nbsp;
            Â© 2024-{CURRENT_YEAR}
            <br>
            Gemini Modeli: <span style="color: {'green' if globals().get('gemini_model') else 'red'};">{st.session_state.gemini_model_name if globals().get('gemini_model') else 'Devre DÄ±ÅŸÄ±'}</span> &nbsp;&nbsp;|&nbsp;&nbsp;
            Supabase Loglama: <span style="color: {'green' if globals().get('supabase') else 'red'};">{'Aktif' if globals().get('supabase') else 'Devre DÄ±ÅŸÄ±'}</span>
        </p>
        """, unsafe_allow_html=True
    )
